"""
Flaskä¸»åº”ç”¨
ç®€æ´çš„APIæœåŠ¡ç«¯ç‚¹
"""
import os
import sys
import json
import logging
import re
import threading
from flask import Flask, request, jsonify, render_template, send_from_directory, session
from flask import Response
from flask_cors import CORS
from datetime import datetime
import uuid as uuid_module

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# æ¸…ç†ä»£ç†ç¯å¢ƒå˜é‡ï¼Œé¿å…LiteLLMå†²çª
for k in ("http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY"):
    os.environ.pop(k, None)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from backend.interpreter_manager import InterpreterManager
from backend.database import DatabaseManager
from backend.prompts import PromptTemplates
from backend.config_loader import ConfigLoader
from backend.history_manager import HistoryManager
from backend.auth import require_auth, optional_auth, auth_manager
from backend.rate_limiter import rate_limit, strict_limiter, cleanup_rate_limiters
from backend.smart_router import SmartRouter
from backend.ai_router import RouteType
from backend.sql_executor import DirectSQLExecutor
from backend.llm_service import LLMService
from backend.api.config_api import config_bp
from backend.cache_manager import CacheManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
FRONTEND_DIR = os.path.join(PROJECT_ROOT, 'frontend')
STATIC_DIR = os.path.join(FRONTEND_DIR, 'static')
TEMPLATE_DIR = os.path.join(FRONTEND_DIR, 'templates')
OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'output')  # ç»Ÿä¸€çš„è¾“å‡ºç›®å½•

# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__, 
            static_folder=STATIC_DIR,
            template_folder=TEMPLATE_DIR,
            static_url_path='/static')

# åˆå§‹åŒ–æ—¥å¿—ï¼ˆæ–‡ä»¶è½®è½¬ã€ç¬¬ä¸‰æ–¹åº“é™å™ªï¼‰
try:
    from backend.log_config import setup_logging, setup_request_logging
    setup_logging(app_name="querygpt", log_dir=os.path.join(PROJECT_ROOT, 'logs'))
    setup_request_logging()
except Exception as _e:
    logger.warning(f"æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {_e}")

# åˆå§‹åŒ–Swaggeræ–‡æ¡£ï¼ˆå¯é€‰ï¼‰
try:
    # ä¿®å¤å¯¼å…¥è·¯å¾„ï¼Œç¡®ä¿ä» backend åŒ…åŠ è½½
    from backend.swagger_config import init_swagger
    swagger = init_swagger(app)
    if swagger:
        print("Swagger documentation initialized at /api/docs")
except ImportError:
    print("Flasgger not installed. Run: pip install flasgger")
except Exception as e:
    print(f"Failed to initialize Swagger: {e}")
# é™åˆ¶CORSæ¥æºä»¥æé«˜å®‰å…¨æ€§ï¼ˆä»ç¯å¢ƒ/é…ç½®è¯»å–å…è®¸çš„æ¥æºï¼‰
try:
    from backend.config_loader import ConfigLoader
    allowed_origins = ConfigLoader.get_config().get('security', {}).get('allowed_origins', []) or [
        'http://localhost:3000', 'http://127.0.0.1:3000'
    ]
except Exception:
    allowed_origins = ['http://localhost:3000', 'http://127.0.0.1:3000']
CORS(app, resources={r"/api/*": {"origins": allowed_origins}})

@app.after_request
def _ensure_cors_headers(resp):
    """ç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸‹ä¹Ÿè¿”å›åŸºç¡€CORSå“åº”å¤´ï¼ˆéµå¾ªç™½åå•ï¼‰ã€‚"""
    try:
        if request.path.startswith('/api/'):
            origin = request.headers.get('Origin')
            if origin and any(origin.startswith(o.rstrip('*')) for o in allowed_origins):
                resp.headers.setdefault('Access-Control-Allow-Origin', origin)
            resp.headers.setdefault('Access-Control-Allow-Methods', 'GET, POST, OPTIONS, DELETE')
            resp.headers.setdefault('Access-Control-Allow-Headers', 'Content-Type, Authorization')
    except Exception:
        pass
    return resp

# åˆå§‹åŒ–ç®¡ç†å™¨
interpreter_manager = None
database_manager = None
history_manager = None
prompt_templates = PromptTemplates()
smart_router = None
sql_executor = None

# å­˜å‚¨æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢ä»»åŠ¡ï¼ˆä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤ï¼‰
active_queries = {}
active_queries_lock = threading.RLock()  # ä½¿ç”¨å¯é‡å…¥é”æ”¯æŒåµŒå¥—è°ƒç”¨

def _get_stop_status(conversation_id):
    """çº¿ç¨‹å®‰å…¨åœ°è·å–åœæ­¢çŠ¶æ€"""
    with active_queries_lock:
        return active_queries.get(conversation_id, {}).get('should_stop', False)

def sync_config_files():
    """ä¸å†å†™å›æ•æ„Ÿä¿¡æ¯åˆ°config.jsonï¼Œä¿æŒ.envä¸ºå”¯ä¸€æ¥æºã€‚"""
    # ä¸ºå…¼å®¹æ—§é€»è¾‘ä¿ç•™ç©ºå®ç°ï¼Œé¿å…å†™å…¥åŒ…å«å¯†ç çš„æ•°æ®åº“é…ç½®åˆ°ç‰ˆæœ¬åº“
    return


def ensure_history_manager(force_reload: bool = False) -> bool:
    """ç¡®ä¿ history_manager å·²åˆå§‹åŒ–ï¼Œå¿…è¦æ—¶é‡è¯•ã€‚"""
    global history_manager
    if history_manager is None or force_reload:
        try:
            init_managers(force_reload=force_reload)
        except Exception as exc:
            logger.error(f"åˆå§‹åŒ– history_manager å¤±è´¥: {exc}")
    return history_manager is not None


def ensure_database_manager(force_reload: bool = False) -> bool:
    """ç¡®ä¿ database_manager å·²å‡†å¤‡å¥½ï¼ˆä¸”å·²é…ç½®ï¼‰ã€‚"""
    global database_manager
    db_ready = database_manager is not None and getattr(database_manager, 'is_configured', True)
    if not db_ready:
        try:
            init_managers(force_reload=force_reload or database_manager is None)
        except Exception as exc:
            logger.error(f"åˆå§‹åŒ– database_manager å¤±è´¥: {exc}")
        db_ready = database_manager is not None and getattr(database_manager, 'is_configured', True)
    return db_ready


def init_managers(force_reload: bool = False):
    """åˆå§‹åŒ–å„ä¸ªç®¡ç†å™¨ï¼Œæ•°æ®åº“æœªé…ç½®æ—¶è‡ªåŠ¨é™çº§"""
    global interpreter_manager, database_manager, history_manager, smart_router, sql_executor

    sync_config_files()

    if force_reload:
        try:
            DatabaseManager.GLOBAL_DISABLED = False
        except Exception:
            pass

    # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨ï¼ˆå…è®¸ç¼ºå¤±é…ç½®ï¼‰
    try:
        db_manager = DatabaseManager()
        if not getattr(db_manager, 'is_configured', True):
            logger.warning("æ•°æ®åº“é…ç½®ç¼ºå¤±ï¼Œç¦ç”¨æ•°æ®åº“ç›¸å…³åŠŸèƒ½")
            db_manager = None
    except RuntimeError as exc:
        logger.warning(f"æ•°æ®åº“æœªé…ç½®: {exc}")
        db_manager = None
    except Exception as exc:
        logger.error(f"æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {exc}")
        db_manager = None
    database_manager = db_manager

    # åˆå§‹åŒ–è§£é‡Šå™¨
    try:
        interpreter_manager = InterpreterManager()
    except Exception as exc:
        logger.error(f"InterpreterManager åˆå§‹åŒ–å¤±è´¥: {exc}")
        interpreter_manager = None

    # SQL æ‰§è¡Œå™¨å¯åœ¨æ•°æ®åº“ç¼ºå¤±æ—¶æä¾›å‹å¥½é”™è¯¯
    sql_executor = DirectSQLExecutor(database_manager)

    # åˆå§‹åŒ–æ™ºèƒ½è·¯ç”±å™¨ï¼Œå¿…è¦æ—¶å›é€€
    try:
        smart_router = SmartRouter(database_manager, interpreter_manager)
    except Exception as exc:
        logger.warning(f"æ™ºèƒ½è·¯ç”±å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤è·¯ç”±: {exc}")
        smart_router = None

    # å†å²è®°å½•ç®¡ç†å™¨
    if force_reload or history_manager is None:
        try:
            history_manager = HistoryManager()
        except Exception as exc:
            logger.error(f"å†å²è®°å½•ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {exc}")
            history_manager = None

    logger.info(
        "ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ: database=%s, interpreter=%s, smart_router=%s",
        bool(database_manager),
        bool(interpreter_manager),
        bool(smart_router)
    )


_BOOTSTRAP_DONE = False

@app.before_request
def _bootstrap_on_first_request():
    """åœ¨é¦–ä¸ªè¯·æ±‚åˆ°è¾¾æ—¶è¿›è¡Œä¸€æ¬¡æ€§åˆå§‹åŒ–ã€‚"""
    global _BOOTSTRAP_DONE
    if _BOOTSTRAP_DONE:
        return
    try:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        os.makedirs('cache', exist_ok=True)
    except Exception:
        pass
    try:
        init_managers()
    except Exception as e:
        logger.error(f"æƒ°æ€§åˆå§‹åŒ–å¤±è´¥: {e}")
    _BOOTSTRAP_DONE = True


def _sse_format(event: str, data: dict) -> str:
    try:
        payload = json.dumps(data, ensure_ascii=False)
    except Exception:
        payload = json.dumps({"message": str(data)})
    return f"event: {event}\n" f"data: {payload}\n\n"


def _generate_progress_plan(user_query: str, route_type: str = 'ai_analysis', language: str = 'zh'):
    """è°ƒç”¨LLMç”Ÿæˆç®€çŸ­è¿›åº¦æ ‡ç­¾ï¼ˆæ¯é¡¹ä¸è¶…è¿‡10å­—ï¼Œ3-6é¡¹ï¼‰ã€‚å¤±è´¥æ—¶è¿”å›é»˜è®¤ã€‚"""
    try:
        svc = LLMService()
        prompt = (
            "ä½ æ˜¯æ•°æ®åˆ†æçš„æ‰§è¡Œè®¡åˆ’åŠ©ç†ã€‚è¯·åŸºäºç”¨æˆ·éœ€æ±‚å’Œæ‰§è¡Œè·¯å¾„ï¼Œç”Ÿæˆä¸€ä¸ªæœ€å¤š6æ­¥çš„è¿›åº¦æ ‡ç­¾åˆ—è¡¨ï¼Œ"
            "æ¯ä¸ªæ ‡ç­¾ä¸è¶…è¿‡10ä¸ªå­—ï¼Œç®€çŸ­ã€å‹å¥½ï¼Œä¾¿äºå±•ç¤ºç»™éæŠ€æœ¯ç”¨æˆ·ã€‚"
            f"\n- ç”¨æˆ·éœ€æ±‚: {user_query[:200]}"
            f"\n- æ‰§è¡Œè·¯å¾„: {route_type.upper()}"
            "\nåªè¾“å‡ºJSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n{\n  \"labels\": [\"å‡†å¤‡\", \"è§£æéœ€æ±‚\", \"æŸ¥è¯¢æ•°æ®\", \"ç”Ÿæˆå›¾è¡¨\", \"æ€»ç»“è¾“å‡º\"]\n}"
        )
        if language == 'en':
            prompt = (
                "You are a progress planner. Based on the user request and execution route, generate 3-6 short step labels"
                ", each no longer than 10 characters, friendly for non-technical users."
                f"\n- User request: {user_query[:200]}"
                f"\n- Route: {route_type.upper()}"
                "\nOutput JSON only in the form:\n{\n  \"labels\": [\"Prepare\", \"Parse\", \"Query\", \"Chart\", \"Summarize\"]\n}"
            )
        res = svc.complete(prompt, temperature=0.2, max_tokens=200)
        if res.get('success'):
            content = res.get('content', '{}')
            data = json.loads(content)
            labels = data.get('labels')
            if isinstance(labels, list) and 1 <= len(labels) <= 8:
                # ç»Ÿä¸€æˆªæ–­
                return [str(x)[:10] for x in labels]
    except Exception:
        pass
    # é»˜è®¤è®¡åˆ’
    return ['å‡†å¤‡', 'è§£æéœ€æ±‚', 'æŸ¥è¯¢æ•°æ®', 'ç”Ÿæˆå›¾è¡¨', 'æ€»ç»“è¾“å‡º'] if language != 'en' else ['Prepare', 'Parse', 'Query', 'Chart', 'Summary']


@app.route('/api/chat/stream', methods=['GET'])
@optional_auth
@rate_limit(max_requests=20, window_seconds=60)
def chat_stream():
    """SSEæµå¼æŸ¥è¯¢ï¼šä»…æ¨é€å‹å¥½çš„è¿›åº¦ä¸æœ€ç»ˆç»“æœï¼Œä¸åŒ…å«ä»£ç ã€‚"""
    try:
        if interpreter_manager is None:
            return Response(_sse_format('error', {"error": "LLM è§£é‡Šå™¨æœªåˆå§‹åŒ–"}), mimetype='text/event-stream')

        # è¯»å–å‚æ•°ï¼ˆEventSourceä¸ºGETï¼‰
        user_query = request.args.get('query', '')
        model_name = request.args.get('model')
        use_database = request.args.get('use_database', 'true').lower() != 'false'
        context_rounds = int(request.args.get('context_rounds', '3') or 3)
        user_language = request.args.get('language', 'zh')
        requested_conversation_id = request.args.get('conversation_id')

        if not user_query:
            return Response(_sse_format('error', {"error": "æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º"}), mimetype='text/event-stream')

        # åˆ›å»ºæˆ–å¤ç”¨ä¼šè¯ID
        conv_id = requested_conversation_id or None
        if history_manager:
            title = user_query[:50] + ('...' if len(user_query) > 50 else '')
            existing_conversation = None
            if conv_id:
                try:
                    existing_conversation = history_manager.get_conversation_history(conv_id)
                except Exception as exc:
                    logger.warning(f"è¯»å–ä¼šè¯ {conv_id} å¤±è´¥ï¼Œåˆ›å»ºæ–°ä¼šè¯: {exc}")
                    existing_conversation = None
            if not conv_id or not existing_conversation:
                conv_id = history_manager.create_conversation(title=title, model=model_name or 'default')
        else:
            conv_id = conv_id or str(uuid_module.uuid4())

        # å¦‚æœæ•°æ®åº“ä¸å¯ç”¨ï¼Œè‡ªåŠ¨é™çº§
        if use_database and not ensure_database_manager():
            logger.warning("è¯·æ±‚ä½¿ç”¨æ•°æ®åº“ï¼Œä½†å½“å‰æ•°æ®åº“ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºçº¯AIæ¨¡å¼")
            use_database = False

        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        if history_manager and conv_id and user_query:
            try:
                history_manager.add_message(
                    conversation_id=conv_id,
                    message_type="user",
                    content=user_query,
                    context={
                        "model": model_name,
                        "use_database": use_database,
                        "context_rounds": context_rounds
                    }
                )
            except Exception as exc:
                logger.warning(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²å¤±è´¥: {exc}")

        # æ ‡è®°æŸ¥è¯¢å¼€å§‹
        with active_queries_lock:
            active_queries[conv_id] = { 'start_time': datetime.now(), 'should_stop': False }

        # è®¾ç½®ä¸Šä¸‹æ–‡è½®æ•°
        if interpreter_manager and context_rounds:
            interpreter_manager.max_history_rounds = context_rounds

        def generate():
            try:
                # èµ·å§‹äº‹ä»¶
                yield _sse_format('progress', { 'stage': 'start', 'message': 'å¼€å§‹å¤„ç†è¯·æ±‚â€¦', 'conversation_id': conv_id })

                # è·¯ç”±é˜¶æ®µ
                # è§„èŒƒåŒ–è·¯ç”±ç±»å‹ä¸ºå°å†™ï¼Œä¿æŒä¸åç«¯æšä¸¾ä¸€è‡´
                route_info = {'route_type': 'ai_analysis', 'confidence': 0}
                config_path = os.path.join(os.path.dirname(__file__), 'config', 'config.json')
                smart_enabled = False
                try:
                    if os.path.exists(config_path):
                        with open(config_path, 'r', encoding='utf-8') as f:
                            cfg = json.load(f)
                            smart_enabled = cfg.get('features', {}).get('smart_routing', {}).get('enabled', False)
                except Exception:
                    smart_enabled = False

                if smart_router and smart_enabled:
                    yield _sse_format('progress', { 'stage': 'classify', 'message': 'æ­£åœ¨åˆ¤æ–­æœ€ä½³æ‰§è¡Œè·¯å¾„â€¦' })
                    router_ctx = {
                        'model_name': model_name,
                        'conversation_id': conv_id,
                        'language': user_language,
                        'use_database': use_database,
                        'context_rounds': context_rounds,
                        'stop_checker': lambda: _get_stop_status(conv_id),
                    }
                    try:
                        classification = smart_router.ai_classifier.classify(user_query, smart_router._prepare_routing_context(router_ctx)) if smart_router.ai_classifier else {}
                        route_type = str(classification.get('route', 'ai_analysis')).lower()
                        route_info['route_type'] = route_type
                        route_info['confidence'] = classification.get('confidence', 0)
                        yield _sse_format('progress', { 'stage': 'route', 'message': f"æ‰§è¡Œè·¯å¾„ï¼š{route_type}", 'route': route_info })
                    except Exception:
                        yield _sse_format('progress', { 'stage': 'route', 'message': 'ä½¿ç”¨é»˜è®¤AIåˆ†æè·¯å¾„' })

                # ç”Ÿæˆè¿›åº¦è®¡åˆ’ï¼ˆçŸ­æ ‡ç­¾ï¼‰
                try:
                    labels = _generate_progress_plan(user_query, route_info.get('route_type', 'ai_analysis'), user_language)
                    yield _sse_format('progress_plan', { 'labels': labels })
                except Exception:
                    pass

                # æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
                context = {}
                if use_database:
                    try:
                        db_config = ConfigLoader.get_database_config()
                        context['connection_info'] = {
                            'host': db_config['host'],
                            'port': db_config['port'],
                            'user': db_config['user'],
                            'password': db_config['password'],
                            'database': db_config.get('database', '')
                        }
                    except Exception:
                        pass

                # å‹å¥½é˜¶æ®µæç¤º
                if route_info.get('route_type') == 'direct_sql':
                    yield _sse_format('progress', { 'stage': 'execute', 'message': 'æ­£åœ¨æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢â€¦' })
                else:
                    yield _sse_format('progress', { 'stage': 'analyze', 'message': 'æ­£åœ¨åˆ†ææ•°æ®ä¸ç”Ÿæˆå›¾è¡¨â€¦' })

                # æ‰§è¡ŒæŸ¥è¯¢
                result = interpreter_manager.execute_query(
                    user_query,
                    context=context,
                    model_name=model_name,
                    conversation_id=conv_id,
                    stop_checker=lambda: _get_stop_status(conv_id),
                    language=user_language
                )

                # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°å†å²
                if history_manager and conv_id:
                    try:
                        assistant_content = result.get('result', result.get('error', 'æ‰§è¡Œå¤±è´¥'))
                        execution_details = None
                        if result.get('success'):
                            execution_details = {
                                "sql": result.get('sql'),
                                "execution_time": result.get('execution_time'),
                                "rows_affected": result.get('rows_count'),
                                "visualization": result.get('visualization'),
                                "model": result.get('model')
                            }
                        if isinstance(assistant_content, dict) and 'content' in assistant_content:
                            content_to_save = json.dumps({"type": "dual_view", "data": assistant_content}, ensure_ascii=False)
                        elif isinstance(assistant_content, list):
                            content_to_save = json.dumps({"type": "raw_output", "data": assistant_content}, ensure_ascii=False)
                        elif not isinstance(assistant_content, str):
                            content_to_save = json.dumps(assistant_content, ensure_ascii=False)
                        else:
                            content_to_save = assistant_content
                        history_manager.add_message(
                            conversation_id=conv_id,
                            message_type="assistant",
                            content=content_to_save,
                            execution_details=execution_details
                        )
                    except Exception as exc:
                        logger.warning(f"ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²å¤±è´¥: {exc}")

                # ç»“æœäº‹ä»¶ï¼ˆä¸åŒ…å«ä»£ç ï¼Œæ²¿ç”¨åç«¯æ±‡æ€»ï¼‰
                yield _sse_format('result', {
                    'success': result.get('success', False),
                    'result': result.get('result') or result.get('error'),
                    'model': result.get('model'),
                    'conversation_id': conv_id
                })

                yield _sse_format('done', { 'conversation_id': conv_id })

            except GeneratorExit:
                # å®¢æˆ·ç«¯æ–­å¼€
                with active_queries_lock:
                    if conv_id in active_queries:
                        active_queries[conv_id]['should_stop'] = True
                if interpreter_manager:
                    interpreter_manager.stop_query(conv_id)
            except Exception as e:
                yield _sse_format('error', { 'error': str(e), 'conversation_id': conv_id })
            finally:
                with active_queries_lock:
                    active_queries.pop(conv_id, None)

        headers = {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
        return Response(generate(), headers=headers)

    except Exception as e:
        return Response(_sse_format('error', { 'error': str(e) }), mimetype='text/event-stream')

# è·¯ç”±å®šä¹‰
@app.route('/')
def index():
    """ä¸»é¡µè·¯ç”±"""
    return render_template('index.html')

@app.route('/test_guide')
def test_guide():
    """å¼•å¯¼æµ‹è¯•é¡µé¢"""
    return send_from_directory(TEMPLATE_DIR, 'test_guide.html')

@app.route('/test_onboarding')
def test_onboarding():
    """æ–°æ‰‹å¼•å¯¼æµ‹è¯•é¡µé¢"""
    import os
    test_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'test_onboarding.html')
    if os.path.exists(test_file):
        return send_from_directory(os.path.dirname(test_file), 'test_onboarding.html')
    return jsonify({"error": "æµ‹è¯•é¡µé¢ä¸å­˜åœ¨"}), 404

@app.route('/debug_onboarding')
def debug_onboarding():
    """æ–°æ‰‹å¼•å¯¼è°ƒè¯•é¡µé¢"""
    return send_from_directory(TEMPLATE_DIR, 'debug_onboarding.html')

@app.route('/config/onboarding_config.json')
def serve_onboarding_config():
    """ä»…å®‰å…¨åœ°å…¬å¼€æ–°æ‰‹å¼•å¯¼é…ç½®ï¼Œé¿å…æ³„éœ²å…¶ä»–é…ç½®æ–‡ä»¶ã€‚"""
    config_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config')
    safe_file = 'onboarding_config.json'
    path = os.path.join(config_dir, safe_file)
    if os.path.exists(path):
        return send_from_directory(config_dir, safe_file)
    return jsonify({"error": "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"}), 404

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "0.4.3"
    })

@app.route('/output/<path:filename>')
def serve_output(filename):
    """å®‰å…¨åœ°æœåŠ¡outputç›®å½•ä¸­çš„HTMLæ–‡ä»¶ - æ”¯æŒè·¨å¹³å°è·¯å¾„"""
    import os.path
    import platform
    
    # 1. è§„èŒƒåŒ–è·¯å¾„ï¼Œç§»é™¤ ../ ç­‰å±é™©å…ƒç´ 
    safe_filename = os.path.normpath(filename)
    
    # 2. æ£€æŸ¥æ˜¯å¦åŒ…å«è·¯å¾„éå†å°è¯•
    if safe_filename.startswith('..') or os.path.isabs(safe_filename):
        logger.warning(f"æ£€æµ‹åˆ°è·¯å¾„éå†å°è¯•: {filename}")
        return jsonify({"error": "éæ³•çš„æ–‡ä»¶è·¯å¾„"}), 403
    
    # 3. åªå…è®¸ç‰¹å®šçš„æ–‡ä»¶æ‰©å±•å
    ALLOWED_EXTENSIONS = {'.html', '.png', '.jpg', '.jpeg', '.svg', '.pdf', '.json', '.csv'}
    file_ext = os.path.splitext(safe_filename)[1].lower()
    if file_ext not in ALLOWED_EXTENSIONS:
        return jsonify({"error": f"ä¸å…è®¸è®¿é—®{file_ext}æ–‡ä»¶"}), 403
    
    # 4. æ„å»ºå®‰å…¨çš„æ–‡ä»¶è·¯å¾„ - æ ¹æ®ç³»ç»Ÿç±»å‹æ·»åŠ ä¸åŒçš„æœç´¢è·¯å¾„
    output_dirs = [
        os.path.join(PROJECT_ROOT, 'backend', 'output'),
        OUTPUT_DIR,
        os.path.join(os.path.dirname(__file__), 'output')
    ]
    
    # æ£€æµ‹ç³»ç»Ÿç±»å‹å¹¶æ·»åŠ ç‰¹å®šè·¯å¾„
    system = platform.system().lower()
    logger.info(f"æ£€æµ‹åˆ°ç³»ç»Ÿç±»å‹: {system}, å¹³å°ä¿¡æ¯: {platform.platform()}")
    
    # Windows æˆ– WSL ç¯å¢ƒ
    if system == 'linux':
        # æ£€æŸ¥æ˜¯å¦æ˜¯ WSL ç¯å¢ƒ
        try:
            with open('/proc/version', 'r') as f:
                version_info = f.read().lower()
                if 'microsoft' in version_info or 'wsl' in version_info:
                    logger.info("æ£€æµ‹åˆ° WSL ç¯å¢ƒï¼Œæ·»åŠ é¢å¤–æœç´¢è·¯å¾„")
                    # WSL ç¯å¢ƒå¯èƒ½çš„æ–‡ä»¶ä½ç½®
                    # æ³¨æ„ï¼šæ–‡ä»¶é€šå¸¸è¿˜æ˜¯åœ¨ Linux ä¾§çš„ output ç›®å½•
                    # ä½†æˆ‘ä»¬ä¹Ÿæ£€æŸ¥å¯èƒ½çš„ Windows è·¯å¾„æ˜ å°„
                    wsl_paths = [
                        '/mnt/c/tmp/output',
                        '/mnt/c/Users/Public/output'
                    ]
                    for wsl_path in wsl_paths:
                        if os.path.exists(wsl_path):
                            output_dirs.append(wsl_path)
        except:
            pass
    
    # Windows åŸç”Ÿç¯å¢ƒ
    elif system == 'windows':
        windows_paths = [
            'C:\\tmp\\output',
            os.path.expanduser('~\\Documents\\QueryGPT\\output')
        ]
        for win_path in windows_paths:
            if os.path.exists(win_path):
                output_dirs.append(win_path)
    
    # macOS ç¯å¢ƒ
    elif system == 'darwin':
        mac_paths = [
            os.path.expanduser('~/Documents/QueryGPT/output'),
            '/tmp/querygpt_output'
        ]
        for mac_path in mac_paths:
            if os.path.exists(mac_path):
                output_dirs.append(mac_path)
    
    logger.debug(f"æœç´¢è·¯å¾„åˆ—è¡¨: {output_dirs}")
    
    for output_dir in output_dirs:
        # ç¡®ä¿è¾“å‡ºç›®å½•æ˜¯ç»å¯¹è·¯å¾„
        output_dir = os.path.abspath(output_dir)
        # æ„å»ºè¯·æ±‚çš„æ–‡ä»¶å®Œæ•´è·¯å¾„
        requested_path = os.path.abspath(os.path.join(output_dir, safe_filename))
        
        # 5. éªŒè¯æœ€ç»ˆè·¯å¾„åœ¨å…è®¸çš„ç›®å½•å†…
        if not requested_path.startswith(output_dir):
            logger.warning(f"è·¯å¾„è¶Šç•Œå°è¯•: {requested_path} ä¸åœ¨ {output_dir} å†…")
            continue
        
        # 6. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶æä¾›æœåŠ¡
        if os.path.exists(requested_path) and os.path.isfile(requested_path):
            logger.info(f"å®‰å…¨æä¾›æ–‡ä»¶: {safe_filename}")
            return send_from_directory(output_dir, safe_filename)
    
    logger.warning(f"æ–‡ä»¶æœªæ‰¾åˆ°: {safe_filename}")
    return jsonify({"error": "æ–‡ä»¶æœªæ‰¾åˆ°"}), 404

def _dynamic_rate_limit(max_requests: int, window_seconds: int):
    def deco(f):
        def wrapper(*args, **kwargs):
            # è¿è¡Œæ—¶è·å–æœ€æ–°çš„ rate_limitï¼ˆæ”¯æŒå•æµ‹ monkeypatchï¼‰
            try:
                from backend import rate_limiter as rl
                rl_func = rl.rate_limit
                try:
                    # ä¼˜å…ˆæŒ‰è£…é¥°å™¨å·¥å‚è°ƒç”¨
                    wrapped = rl_func(max_requests=max_requests, window_seconds=window_seconds)(f)
                except TypeError:
                    # å…¼å®¹æµ‹è¯•æ¡©ï¼šrl.rate_limit(f)
                    wrapped = rl_func(f)
                return wrapped(*args, **kwargs)
            except Exception:
                return f(*args, **kwargs)
        # ä¿ç•™å…ƒæ•°æ®
        try:
            from functools import wraps
            return wraps(f)(wrapper)
        except Exception:
            return wrapper
    return deco

@app.route('/api/chat', methods=['POST'])
@optional_auth  # ä½¿ç”¨å¯é€‰è®¤è¯ï¼Œå…è®¸é€æ­¥è¿ç§»
@_dynamic_rate_limit(max_requests=30, window_seconds=60)  # æ”¯æŒè¿è¡Œæ—¶æ‰“æ¡©
def chat():
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    try:
        # æƒ°æ€§åˆå§‹åŒ–ï¼ˆé¿å…æµ‹è¯•ç¯å¢ƒç›´æ¥500ï¼‰
        global interpreter_manager
        if interpreter_manager is None:
            try:
                init_managers()
            except Exception:
                logger.error("InterpreterManager æœªåˆå§‹åŒ–")
                # ç»§ç»­æ‰§è¡Œä»¥ä¾¿è¿”å›å¯ç†è§£çš„é”™è¯¯
        
        data = request.get_json(silent=True) or {}
        # å…¼å®¹ message å­—æ®µ
        user_query = data.get('query') or data.get('message') or ''
        from backend.config_loader import ConfigLoader
        model_name = ConfigLoader.normalize_model_id(data.get('model')) if data.get('model') else None

        if not ensure_history_manager() and data.get('use_history', True):
            logger.warning("å†å²è®°å½•æœªå¯ç”¨ï¼ŒèŠå¤©è®°å½•å°†ä¸ä¼šè¢«ä¿å­˜")
        use_database = data.get('use_database', True)
        conversation_id = data.get('conversation_id')  # è·å–ä¼šè¯ID
        context_rounds = data.get('context_rounds', 3)  # è·å–ä¸Šä¸‹æ–‡è½®æ•°ï¼Œé»˜è®¤3
        user_language = data.get('language', 'zh')  # è·å–ç”¨æˆ·è¯­è¨€ï¼Œé»˜è®¤ä¸­æ–‡
        # ç®€æ˜“SSEå…¼å®¹ï¼šå½“è¯·æ±‚æ ‡æ³¨ stream=True æ—¶ï¼Œç›´æ¥è¿”å›æœ€å°SSE
        if data.get('stream') is True:
            def _mini_stream():
                yield "data: {\"status\": \"processing\"}\n\n"
                yield "data: {\"status\": \"done\"}\n\n"
            return Response(_mini_stream(), mimetype='text/event-stream')
        
        # å¦‚æœæ²¡æœ‰æä¾›ä¼šè¯IDï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„å¹¶åœ¨å†å²è®°å½•ä¸­åˆ›å»º
        is_new_conversation = not conversation_id
        if not conversation_id:
            # åˆ›å»ºæ–°çš„å¯¹è¯è®°å½•
            if history_manager:
                # æ£€æµ‹ç”¨æˆ·æŸ¥è¯¢è¯­è¨€ï¼Œä½¿ç”¨é€‚å½“çš„å‰ç¼€
                import re
                # ç®€å•æ£€æµ‹æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
                has_chinese = bool(re.search(r'[\u4e00-\u9fff]', user_query))
                query_prefix = "æŸ¥è¯¢: " if has_chinese else "Query: "
                
                # åˆ›å»ºæ ‡é¢˜
                title = f"{query_prefix}{user_query[:50]}..." if len(user_query) > 50 else user_query
                
                conversation_id = history_manager.create_conversation(
                    title=title,
                    model=model_name or "default",
                    database_name=data.get('database')
                )
                logger.info(f"åˆ›å»ºæ–°å¯¹è¯: {conversation_id}")
            else:
                conversation_id = str(uuid_module.uuid4())
                logger.warning("history_manageræœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ä¸´æ—¶ID")
        
        # è®¾ç½®ä¸Šä¸‹æ–‡è½®æ•°
        if interpreter_manager and context_rounds:
            interpreter_manager.max_history_rounds = context_rounds
        
        if not user_query:
            return jsonify({"error": "message is required"}), 400
        
        logger.info(f"æ”¶åˆ°æŸ¥è¯¢: {user_query[:100]}...")
        
        # ç®€å•çš„æ„å›¾è¯†åˆ«
        greetings = ['ä½ å¥½', 'hello', 'hi', 'æ—©ä¸Šå¥½', 'ä¸‹åˆå¥½', 'æ™šä¸Šå¥½', 'å—¨']
        farewells = ['å†è§', 'æ‹œæ‹œ', 'bye', 'goodbye', 'æ™šå®‰']
        
        query_lower = user_query.lower().strip()
        
        # å¦‚æœæ˜¯é—®å€™è¯­
        if any(greeting in query_lower for greeting in greetings):
            # å³ä½¿æ˜¯é—®å€™è¯­ï¼Œä¹Ÿè¦ä¿å­˜åˆ°å†å²è®°å½•
            if history_manager and conversation_id:
                history_manager.add_message(
                    conversation_id=conversation_id,
                    message_type="user",
                    content=user_query,
                    context={"model": model_name, "type": "greeting"}
                )
                
                greeting_response = "QueryGPT æ•°æ®åˆ†æç³»ç»Ÿ\n\nå¯æä¾›ï¼š\nâ€¢ æ•°æ®åº“æŸ¥è¯¢åˆ†æ\nâ€¢ å›¾è¡¨ç”Ÿæˆï¼ˆæŸ±çŠ¶å›¾ã€é¥¼å›¾ã€æŠ˜çº¿å›¾ï¼‰\nâ€¢ æ•°æ®æŠ¥è¡¨å¯¼å‡º\n\nç¤ºä¾‹æŸ¥è¯¢ï¼š\n- æŸ¥è¯¢ä¸Šæœˆé”€å”®æ•°æ®\n- æŒ‰éƒ¨é—¨ç»Ÿè®¡ä»Šå¹´ä¸šç»©\n- ç”Ÿæˆäº§å“é”€é‡è¶‹åŠ¿å›¾"
                
                history_manager.add_message(
                    conversation_id=conversation_id,
                    message_type="assistant",
                    content=greeting_response
                )
            
            return jsonify({
                "success": True,
                "result": {
                    "content": [{
                        "type": "text",
                        "content": "QueryGPT æ•°æ®åˆ†æç³»ç»Ÿ\n\nå¯æä¾›ï¼š\nâ€¢ æ•°æ®åº“æŸ¥è¯¢åˆ†æ\nâ€¢ å›¾è¡¨ç”Ÿæˆï¼ˆæŸ±çŠ¶å›¾ã€é¥¼å›¾ã€æŠ˜çº¿å›¾ï¼‰\nâ€¢ æ•°æ®æŠ¥è¡¨å¯¼å‡º\n\nç¤ºä¾‹æŸ¥è¯¢ï¼š\n- æŸ¥è¯¢ä¸Šæœˆé”€å”®æ•°æ®\n- æŒ‰éƒ¨é—¨ç»Ÿè®¡ä»Šå¹´ä¸šç»©\n- ç”Ÿæˆäº§å“é”€é‡è¶‹åŠ¿å›¾"
                    }]
                },
                "model": model_name or "system",
                "conversation_id": conversation_id,  # æ·»åŠ conversation_id
                "timestamp": datetime.now().isoformat()
            })
        
        # å¦‚æœæ˜¯å‘Šåˆ«è¯­
        if any(farewell in query_lower for farewell in farewells):
            # ä¿å­˜å‘Šåˆ«è¯­åˆ°å†å²è®°å½•
            if history_manager and conversation_id:
                history_manager.add_message(
                    conversation_id=conversation_id,
                    message_type="user",
                    content=user_query,
                    context={"model": model_name, "type": "farewell"}
                )
                
                farewell_response = "ä¼šè¯ç»“æŸ"
                
                history_manager.add_message(
                    conversation_id=conversation_id,
                    message_type="assistant",
                    content=farewell_response
                )
            
            return jsonify({
                "success": True,
                "result": {
                    "content": [{
                        "type": "text",
                        "content": "ä¼šè¯ç»“æŸ"
                    }]
                },
                "model": model_name or "system",
                "conversation_id": conversation_id,  # æ·»åŠ conversation_id
                "timestamp": datetime.now().isoformat()
            })
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        context = {}
        
        if use_database:
            if not ensure_database_manager():
                logger.warning("è¯·æ±‚ä½¿ç”¨æ•°æ®åº“ï¼Œä½†æœªæ£€æµ‹åˆ°æœ‰æ•ˆé…ç½®ï¼Œè‡ªåŠ¨é™çº§ä¸ºéæ•°æ®åº“æ¨¡å¼")
                use_database = False
                full_query = user_query
            else:
                full_query = user_query

                from backend.config_loader import ConfigLoader
                db_config = ConfigLoader.get_database_config()

                context['connection_info'] = {
                    'host': db_config['host'],
                    'port': db_config['port'],
                    'user': db_config['user'],
                    'password': db_config['password'],
                    'database': db_config.get('database', '')
                }

                if (
                    getattr(database_manager, 'is_configured', False)
                    and not DatabaseManager.GLOBAL_DISABLED
                ):
                    try:
                        db_list = database_manager.get_database_list()
                        context['available_databases'] = db_list
                    except Exception as e:
                        logger.warning(f"è·å–æ•°æ®åº“åˆ—è¡¨å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ: {e}")
        else:
            full_query = user_query
        
        # æ ‡è®°æŸ¥è¯¢å¼€å§‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        with active_queries_lock:
            active_queries[conversation_id] = {
                'start_time': datetime.now(),
                'should_stop': False
            }
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²è®°å½•
        if history_manager and conversation_id:
            history_manager.add_message(
                conversation_id=conversation_id,
                message_type="user",
                content=user_query,
                context={
                    "model": model_name,
                    "use_database": use_database,
                    "context_rounds": context_rounds
                }
            )
        
        try:
            # æ£€æŸ¥æ™ºèƒ½è·¯ç”±æ˜¯å¦å¯ç”¨
            import json
            config_path = os.path.join(os.path.dirname(__file__), 'config', 'config.json')
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            else:
                config = {}
            smart_routing_enabled = config.get('features', {}).get('smart_routing', {}).get('enabled', False)
            
            # ä½¿ç”¨æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ
            if smart_router and smart_routing_enabled:
                logger.info("ğŸš€ ä½¿ç”¨æ™ºèƒ½è·¯ç”±ç³»ç»Ÿå¤„ç†æŸ¥è¯¢ [BETA]")
                # å‡†å¤‡è·¯ç”±ä¸Šä¸‹æ–‡
                router_context = {
                    'model_name': model_name,
                    'conversation_id': conversation_id,
                    'language': user_language,
                    'use_database': use_database,
                    'context_rounds': context_rounds,
                    'stop_checker': lambda: _get_stop_status(conversation_id),
                    'connection_info': context.get('connection_info', {})  # å®‰å…¨è®¿é—®ï¼Œé¿å…KeyError
                }
                
                # æ™ºèƒ½è·¯ç”±å¤„ç†
                result = smart_router.route(full_query, router_context)
                
                # å¦‚æœè·¯ç”±è¿”å›äº†query_typeï¼Œè®°å½•ç»Ÿè®¡
                if 'query_type' in result:
                    logger.info(f"ğŸ“Š æŸ¥è¯¢ç±»å‹: {result['query_type']}, æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 'N/A')}s")
                    # åœ¨ç»“æœä¸­æ ‡è®°ä½¿ç”¨äº†æ™ºèƒ½è·¯ç”±
                    result['smart_routing_used'] = True
            else:
                # é™çº§åˆ°åŸæœ‰æµç¨‹
                if not smart_routing_enabled:
                    logger.info("æ™ºèƒ½è·¯ç”±å·²ç¦ç”¨ï¼Œä½¿ç”¨æ ‡å‡†AIæµç¨‹")
                else:
                    logger.info("æ™ºèƒ½è·¯ç”±æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨æ ‡å‡†AIæµç¨‹")
                    
                result = interpreter_manager.execute_query(
                    full_query, 
                    context=context,
                    model_name=model_name,
                    conversation_id=conversation_id,  # ä¼ é€’ä¼šè¯ID
                    stop_checker=lambda: _get_stop_status(conversation_id),
                    language=user_language  # ä¼ é€’è¯­è¨€è®¾ç½®
                )
                result['smart_routing_used'] = False
        finally:
            # æ¸…ç†æ´»è·ƒæŸ¥è¯¢è®°å½•ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            with active_queries_lock:
                if conversation_id in active_queries:
                    del active_queries[conversation_id]
        
        # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°å†å²è®°å½•
        if history_manager and conversation_id:
            execution_details = None
            assistant_content = result.get('result', result.get('error', 'æ‰§è¡Œå¤±è´¥'))
            
            if result.get('success'):
                execution_details = {
                    "sql": result.get('sql'),
                    "execution_time": result.get('execution_time'),
                    "rows_affected": result.get('rows_count'),
                    "visualization": result.get('visualization'),
                    "model": result.get('model')
                }
            
            # ä¿å­˜å®Œæ•´çš„ç»“æœç»“æ„ï¼Œä»¥ä¾¿æ¢å¤åŒè§†å›¾
            # å¦‚æœcontentæ˜¯åŒ…å«role/type/formatçš„æ•°ç»„ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if isinstance(assistant_content, dict) and 'content' in assistant_content:
                # è¿™æ˜¯åŒè§†å›¾æ ¼å¼ï¼Œä¿å­˜æ•´ä¸ªç»“æ„
                content_to_save = json.dumps({
                    "type": "dual_view",
                    "data": assistant_content
                })
            elif isinstance(assistant_content, list):
                # è¿™æ˜¯åŸå§‹çš„OpenInterpreterè¾“å‡ºæ•°ç»„
                content_to_save = json.dumps({
                    "type": "raw_output",
                    "data": assistant_content
                })
            elif not isinstance(assistant_content, str):
                content_to_save = json.dumps(assistant_content)
            else:
                content_to_save = assistant_content
            
            history_manager.add_message(
                conversation_id=conversation_id,
                message_type="assistant",
                content=content_to_save,
                execution_details=execution_details
            )
        
        if result['success']:
            # å…¼å®¹å•æµ‹å­—æ®µï¼šresponse/sql
            resp_payload = {
                "success": True,
                "result": result['result'],
                "model": result['model'],
                "conversation_id": conversation_id,
                "timestamp": datetime.now().isoformat()
            }
            # å°è¯•ä»ç»“æœä¸­æå–sqlæˆ–æ‹¼è£…å“åº”æ–‡æœ¬
            sql_text = result.get('sql')
            if not sql_text and isinstance(result.get('result'), list):
                # æŸ¥æ‰¾ç±»å‹ä¸ºcodeä¸”formatä¸ºsqlçš„ç‰‡æ®µ
                for item in result['result']:
                    if isinstance(item, dict) and item.get('type') == 'code' and item.get('format') == 'sql':
                        sql_text = item.get('content')
                        break
            resp_payload['sql'] = sql_text
            # response æ–‡æœ¬
            if isinstance(result.get('result'), list):
                parts = []
                for item in result['result']:
                    content = item.get('content') if isinstance(item, dict) else None
                    if content:
                        parts.append(str(content))
                resp_payload['response'] = '\n'.join(parts)[:2000]
            else:
                resp_payload['response'] = str(result.get('result'))[:2000]
            return jsonify(resp_payload)
        elif result.get('interrupted'):
            # æŸ¥è¯¢è¢«ä¸­æ–­ï¼Œæ¸…ç†æ‰ä»…æœ‰çš„ç”¨æˆ·æ¶ˆæ¯ï¼Œé¿å…æ®‹ç•™å•å‘è®°å½•
            if history_manager and conversation_id:
                try:
                    history_manager.remove_last_message(conversation_id, message_type='user', delete_empty=False)
                except Exception as cleanup_err:
                    logger.warning(f"æ¸…ç†ä¸­æ–­æ¶ˆæ¯å¤±è´¥: {cleanup_err}")
            # è¿”å›éƒ¨åˆ†ç»“æœ
            return jsonify({
                "success": False,
                "interrupted": True,
                "error": result.get('error', 'æŸ¥è¯¢è¢«ç”¨æˆ·ä¸­æ–­'),
                "model": result['model'],
                "conversation_id": conversation_id,
                "partial_result": result.get('partial_result'),  # å¦‚æœæœ‰éƒ¨åˆ†ç»“æœ
                "timestamp": datetime.now().isoformat()
            }), 200  # è¿”å›200çŠ¶æ€ç ï¼Œå› ä¸ºè¿™æ˜¯æ­£å¸¸çš„ç”¨æˆ·æ“ä½œ
        else:
            return jsonify({
                "success": False,
                "error": result['error'],
                "model": result['model'],
                "conversation_id": conversation_id,  # è¿”å›ä¼šè¯ID
                "timestamp": datetime.now().isoformat()
            }), 500
            
    except Exception as e:
        logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

app.register_blueprint(config_bp)

@app.route('/api/schema', methods=['GET'])
def get_schema():
    """è·å–æ•°æ®åº“ç»“æ„"""
    try:
        if not ensure_database_manager():
            return jsonify({"error": "æ•°æ®åº“æœªé…ç½®"}), 503
            
        schema = database_manager.get_database_schema()
        return jsonify({
            "schema": schema,
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“ç»“æ„å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/test_connection', methods=['GET'])
def test_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        if not ensure_database_manager():
            return jsonify({
                "connected": False,
                "error": "æ•°æ®åº“æœªé…ç½®",
                "test_queries": []
            }), 503
            
        test_result = database_manager.test_connection()
        test_result["timestamp"] = datetime.now().isoformat()
        
        # è®°å½•æµ‹è¯•ç»“æœ
        if test_result["connected"]:
            logger.info(f"æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ: {test_result['host']}:{test_result['port']}")
        else:
            logger.warning(f"æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {test_result.get('error', 'Unknown error')}")
            
        return jsonify(test_result)
    except Exception as e:
        logger.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return jsonify({
            "connected": False,
            "error": str(e),
            "test_queries": []
        })

@app.route('/api/test_model', methods=['POST'])
def test_model():
    """æµ‹è¯•æ¨¡å‹è¿æ¥"""
    try:
        data = request.json
        model_id = data.get('model')
        payload = {
            'model': model_id,
            'id': data.get('id', model_id),
            'api_key': data.get('api_key'),
            'api_base': data.get('api_base'),
            'provider': data.get('provider') or data.get('type'),
            'model_name': data.get('model_name'),
            'litellm_model': data.get('litellm_model')
        }
        success, message = LLMService.test_model_connection(payload)
        return jsonify({
            "success": success,
            "message": message
        })
    except Exception as e:
        logger.error(f"æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "message": f"æµ‹è¯•å¤±è´¥: {str(e)}"
        }), 500

@app.route('/api/routing-stats', methods=['GET'])
def get_routing_stats():
    """è·å–æ™ºèƒ½è·¯ç”±ç»Ÿè®¡ä¿¡æ¯"""
    try:
        if smart_router:
            stats = smart_router.get_routing_stats()
            
            # å…¼å®¹å‰ç«¯æœŸæœ›çš„å­—æ®µåç§°ï¼ˆä»æ–°çš„å­—æ®µæ˜ å°„åˆ°æ—§çš„å‰ç«¯å­—æ®µï¼‰
            stats['simple_queries'] = stats.get('direct_sql_queries', 0)
            stats['ai_queries'] = stats.get('ai_analysis_queries', 0)
            
            # è®¡ç®—é¢å¤–çš„ç»Ÿè®¡ä¿¡æ¯
            if stats['total_queries'] > 0:
                stats['avg_time_saved_per_query'] = stats['total_time_saved'] / stats['total_queries']
                stats['routing_efficiency'] = (stats['simple_queries'] / stats['total_queries']) * 100
            else:
                stats['avg_time_saved_per_query'] = 0
                stats['routing_efficiency'] = 0
            
            return jsonify({
                "success": True,
                "stats": stats,
                "enabled": True
            })
        else:
            return jsonify({
                "success": True,
                "stats": {
                    "total_queries": 0,
                    "simple_queries": 0,
                    "ai_queries": 0,
                    "cache_hits": 0,
                    "total_time_saved": 0
                },
                "enabled": False,
                "message": "æ™ºèƒ½è·¯ç”±ç³»ç»Ÿæœªå¯ç”¨"
            })
    except Exception as e:
        logger.error(f"è·å–è·¯ç”±ç»Ÿè®¡å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/config', methods=['GET', 'POST'])
def handle_config():
    """å·²è¿ç§»è‡³Blueprint: backend.api.config_api.handle_config"""
    from backend.api.config_api import handle_config as _handle
    return _handle()
    
    if request.method == 'GET':
        try:
            # ä¼˜å…ˆèµ°èšåˆé…ç½®ï¼Œä¾¿äºæµ‹è¯•æ¡©ï¼›åŒæ—¶è¡¥å……å‰ç«¯æ—§å­—æ®µä»¥å…¼å®¹
            try:
                cfg = ConfigLoader.get_config()
                if isinstance(cfg, dict) and 'api' in cfg:
                    api = cfg.get('api', {})
                    # å…¼å®¹æ—§å‰ç«¯ï¼šæ·»åŠ é¡¶å±‚ api_key/api_base/default_model
                    cfg.setdefault('api_key', api.get('key', ''))
                    cfg.setdefault('api_base', api.get('base_url', ''))
                    cfg.setdefault('default_model', api.get('model', ''))
                return jsonify(cfg)
            except Exception:
                pass

            # å›é€€åˆ°åŸå®ç°
            api_config = ConfigLoader.get_api_config()
            db_config = ConfigLoader.get_database_config()

            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    full_config = json.load(f)
            except:
                full_config = {}

            config = {
                "api_key": api_config["api_key"],
                "api_base": api_config["api_base"],
                "default_model": api_config["default_model"],
                "models": [
                    {"id": "gpt-4.1", "name": "GPT-4.1", "type": "openai"},
                    {"id": "claude-sonnet-4", "name": "Claude Sonnet 4", "type": "anthropic"},
                    {"id": "deepseek-r1", "name": "DeepSeek R1", "type": "deepseek"},
                    {"id": "qwen-flagship", "name": "Qwen æ——èˆ°æ¨¡å‹", "type": "qwen"}
                ],
                "database": db_config,
                "features": full_config.get("features", {})
            }

            if os.path.exists(config_path):
                try:
                    with open(config_path, 'r') as f:
                        saved_config = json.load(f)
                        for key in ['interface_language', 'interface_theme', 'auto_run_code', 'show_thinking',
                                   'context_rounds', 'default_view_mode']:
                            if key in saved_config:
                                config[key] = saved_config[key]
                except:
                    pass

            return jsonify(config)
        except Exception as e:
            logger.error(f"è¯»å–é…ç½®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    else:  # POST - ä¿å­˜é…ç½®
        try:
            config = request.json
            
            # æ›´æ–°.envæ–‡ä»¶ä¸­çš„å€¼ï¼ˆå¦‚æœæä¾›ï¼‰
            if 'api_key' in config or 'api_base' in config or 'database' in config:
                env_path = os.path.join(PROJECT_ROOT, '.env')
                env_lines = []
                
                # è¯»å–ç°æœ‰çš„.envæ–‡ä»¶
                if os.path.exists(env_path):
                    with open(env_path, 'r') as f:
                        env_lines = f.readlines()
                
                # æ›´æ–°ç›¸åº”çš„å€¼
                updated = False
                new_lines = []
                for line in env_lines:
                    if line.startswith('API_KEY=') and 'api_key' in config:
                        new_lines.append(f"API_KEY={config['api_key']}\n")
                        updated = True
                    elif line.startswith('API_BASE_URL=') and 'api_base' in config:
                        new_lines.append(f"API_BASE_URL={config['api_base']}\n")
                        updated = True
                    elif line.startswith('DEFAULT_MODEL=') and 'default_model' in config:
                        new_lines.append(f"DEFAULT_MODEL={config['default_model']}\n")
                        updated = True
                    elif line.startswith('DB_HOST=') and config.get('database', {}).get('host'):
                        new_lines.append(f"DB_HOST={config['database']['host']}\n")
                        updated = True
                    elif line.startswith('DB_PORT=') and config.get('database', {}).get('port'):
                        new_lines.append(f"DB_PORT={config['database']['port']}\n")
                        updated = True
                    elif line.startswith('DB_USER=') and config.get('database', {}).get('user'):
                        new_lines.append(f"DB_USER={config['database']['user']}\n")
                        updated = True
                    elif line.startswith('DB_PASSWORD=') and 'password' in config.get('database', {}):
                        new_lines.append(f"DB_PASSWORD={config['database']['password']}\n")
                        updated = True
                    elif line.startswith('DB_DATABASE=') and 'database' in config.get('database', {}):
                        new_lines.append(f"DB_DATABASE={config['database'].get('database', '')}\n")
                        updated = True
                    else:
                        new_lines.append(line)
                
                # å†™å›.envæ–‡ä»¶
                if updated:
                    with open(env_path, 'w') as f:
                        f.writelines(new_lines)
            
            # åŒæ—¶ä¿å­˜åˆ°config.json
            os.makedirs(os.path.dirname(config_path), exist_ok=True)
            with open(config_path, 'w') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # é‡æ–°åˆå§‹åŒ–ç®¡ç†å™¨ä»¥ä½¿ç”¨æ–°é…ç½®
            init_managers(force_reload=True)
            
            return jsonify({"success": True, "message": "é…ç½®å·²ä¿å­˜"})
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500

@app.route('/api/database/test', methods=['POST'])
def test_database():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        config = request.json
        
        # å¤„ç†localhoståˆ°127.0.0.1çš„è½¬æ¢ï¼ˆmacOSå…¼å®¹æ€§ï¼‰
        if config.get('host') == 'localhost':
            config['host'] = '127.0.0.1'
        
        # åˆ›å»ºä¸´æ—¶çš„æ•°æ®åº“ç®¡ç†å™¨è¿›è¡Œæµ‹è¯•
        import pymysql
        
        try:
            # ç›´æ¥æµ‹è¯•è¿æ¥
            connection = pymysql.connect(
                host=config.get('host', '127.0.0.1'),
                port=int(config.get('port', 3306)),
                user=config.get('user'),
                password=config.get('password'),
                database=config.get('database', ''),
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )
            
            # è·å–è¡¨æ•°é‡æˆ–æ•°æ®åº“åˆ—è¡¨
            with connection.cursor() as cursor:
                if config.get('database'):
                    # æŒ‡å®šäº†æ•°æ®åº“ï¼Œæ˜¾ç¤ºè¯¥æ•°æ®åº“çš„è¡¨
                    cursor.execute("SHOW TABLES")
                    tables = cursor.fetchall()
                    table_count = len(tables)
                    message = f"è¿æ¥æˆåŠŸï¼Œå‘ç° {table_count} ä¸ªè¡¨"
                else:
                    # æœªæŒ‡å®šæ•°æ®åº“ï¼Œç»Ÿè®¡æ‰€æœ‰æ•°æ®åº“çš„è¡¨
                    cursor.execute("SHOW DATABASES")
                    databases = cursor.fetchall()
                    db_list = [db[list(db.keys())[0]] for db in databases]
                    # è¿‡æ»¤ç³»ç»Ÿæ•°æ®åº“
                    user_databases = [db for db in db_list if db not in ['information_schema', 'mysql', 'performance_schema', 'sys', '__internal_schema']]
                    
                    # ç»Ÿè®¡æ‰€æœ‰ç”¨æˆ·æ•°æ®åº“çš„è¡¨æ€»æ•°
                    total_table_count = 0
                    for db_name in user_databases:
                        try:
                            cursor.execute(f"SELECT COUNT(*) as cnt FROM information_schema.tables WHERE table_schema = '{db_name}'")
                            result = cursor.fetchone()
                            total_table_count += result.get('cnt', 0)
                        except:
                            pass
                    
                    table_count = total_table_count
                    message = f"è¿æ¥æˆåŠŸï¼å¯è®¿é—® {len(user_databases)} ä¸ªæ•°æ®åº“ï¼Œå…± {total_table_count} ä¸ªè¡¨"
            
            connection.close()
            
            return jsonify({
                "success": True,
                "message": "è¿æ¥æˆåŠŸ" if config.get('database') else message,
                "table_count": table_count
            })
            
        except Exception as conn_error:
            error_msg = str(conn_error)
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
            if "Can't connect" in error_msg:
                if "nodename nor servname provided" in error_msg:
                    error_msg = "æ— æ³•è§£æä¸»æœºåï¼Œè¯·å°è¯•ä½¿ç”¨ 127.0.0.1 ä»£æ›¿ localhost"
                elif "Connection refused" in error_msg:
                    error_msg = "è¿æ¥è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“æœåŠ¡æ˜¯å¦è¿è¡Œä»¥åŠç«¯å£æ˜¯å¦æ­£ç¡®"
            elif "Access denied" in error_msg:
                error_msg = "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"
                
            return jsonify({
                "success": False,
                "message": f"è¿æ¥å¤±è´¥: {error_msg}",
                "table_count": 0
            })
            
    except Exception as e:
        logger.error(f"æ•°æ®åº“æµ‹è¯•è¿æ¥å¤±è´¥: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route('/api/database/config', methods=['POST'])
def save_database_config():
    """ä¿å­˜æ•°æ®åº“é…ç½®åˆ°.envæ–‡ä»¶"""
    try:
        config = request.json
        
        # å¤„ç†localhoståˆ°127.0.0.1çš„è½¬æ¢
        if config.get('host') == 'localhost':
            config['host'] = '127.0.0.1'
        
        # è¯»å–ç°æœ‰çš„.envæ–‡ä»¶
        from pathlib import Path
        env_path = Path(__file__).parent.parent / '.env'
        env_lines = []
        
        if env_path.exists():
            with open(env_path, 'r') as f:
                env_lines = f.readlines()
        
        # æ›´æ–°æ•°æ®åº“é…ç½®è¡Œ
        config_map = {
            'DB_HOST': config.get('host', '127.0.0.1'),
            'DB_PORT': str(config.get('port', 3306)),
            'DB_USER': config.get('user', ''),
            'DB_PASSWORD': config.get('password', ''),
            'DB_DATABASE': config.get('database', '')
        }
        
        # åˆ›å»ºæ–°çš„é…ç½®è¡Œ
        new_lines = []
        db_section_found = False
        
        for line in env_lines:
            # è·³è¿‡æ—§çš„æ•°æ®åº“é…ç½®è¡Œ
            if any(line.startswith(f"{key}=") for key in config_map.keys()):
                db_section_found = True
                continue
            # åœ¨æ•°æ®åº“é…ç½®æ³¨é‡Šåæ’å…¥æ–°é…ç½®
            if line.startswith("# æ•°æ®åº“é…ç½®") and not db_section_found:
                new_lines.append(line)
                new_lines.append(f"DB_HOST={config_map['DB_HOST']}\n")
                new_lines.append(f"DB_PORT={config_map['DB_PORT']}\n")
                new_lines.append(f"DB_USER={config_map['DB_USER']}\n")
                new_lines.append(f"DB_PASSWORD={config_map['DB_PASSWORD']}\n")
                new_lines.append(f"DB_DATABASE={config_map['DB_DATABASE']}\n")
                db_section_found = True
            else:
                new_lines.append(line)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ•°æ®åº“é…ç½®éƒ¨åˆ†ï¼Œåœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
        if not db_section_found:
            db_config_lines = [
                "# æ•°æ®åº“é…ç½®\n",
                f"DB_HOST={config_map['DB_HOST']}\n",
                f"DB_PORT={config_map['DB_PORT']}\n",
                f"DB_USER={config_map['DB_USER']}\n",
                f"DB_PASSWORD={config_map['DB_PASSWORD']}\n",
                f"DB_DATABASE={config_map['DB_DATABASE']}\n",
                "\n"
            ]
            new_lines = db_config_lines + new_lines
        
        # å¤‡ä»½ç°æœ‰æ–‡ä»¶
        if env_path.exists():
            backup_path = env_path.with_suffix('.env.backup')
            import shutil
            shutil.copy(env_path, backup_path)
        
        # å†™å…¥æ–°é…ç½®
        with open(env_path, 'w') as f:
            f.writelines(new_lines)
        
        # åŒæ—¶æ›´æ–°config.jsonä¸­çš„æ•°æ®åº“é…ç½®
        config_json_path = os.path.join(PROJECT_ROOT, 'config', 'config.json')
        if os.path.exists(config_json_path):
            try:
                with open(config_json_path, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                # æ›´æ–°æ•°æ®åº“é…ç½®éƒ¨åˆ†
                config_data['database'] = {
                    'host': config_map['DB_HOST'],
                    'port': int(config_map['DB_PORT']),
                    'user': config_map['DB_USER'],
                    'password': config_map['DB_PASSWORD'],
                    'database': config_map['DB_DATABASE']
                }
                
                # å†™å›config.json
                with open(config_json_path, 'w', encoding='utf-8') as f:
                    json.dump(config_data, f, indent=2, ensure_ascii=False)
                    
                logger.info("å·²åŒæ­¥æ›´æ–°config.jsonä¸­çš„æ•°æ®åº“é…ç½®")
            except Exception as e:
                logger.warning(f"æ›´æ–°config.jsonå¤±è´¥ï¼Œä½†.envå·²æ›´æ–°: {e}")
        
        # é‡æ–°åŠ è½½é…ç½®
        global database_manager
        from backend.database import DatabaseManager
        DatabaseManager.GLOBAL_DISABLED = False
        database_manager = DatabaseManager()
        if not getattr(database_manager, 'is_configured', True):
            logger.warning("æ•°æ®åº“é…ç½®ä¿å­˜åä»ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ .env")
            database_manager = None
        
        return jsonify({
            "success": True,
            "message": "æ•°æ®åº“é…ç½®å·²ä¿å­˜"
        })
        
    except Exception as e:
        logger.error(f"ä¿å­˜æ•°æ®åº“é…ç½®å¤±è´¥: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route('/api/stop_query', methods=['POST'])
def stop_query():
    """åœæ­¢æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢"""
    try:
        data = request.json
        conversation_id = data.get('conversation_id')
        
        logger.info(f"æ”¶åˆ°åœæ­¢æŸ¥è¯¢è¯·æ±‚: conversation_id={conversation_id}")
        
        if not conversation_id:
            logger.warning("åœæ­¢æŸ¥è¯¢è¯·æ±‚ç¼ºå°‘ä¼šè¯ID")
            return jsonify({"error": "éœ€è¦æä¾›ä¼šè¯ID"}), 400
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        query_found = False
        with active_queries_lock:
            logger.info(f"å½“å‰æ´»åŠ¨æŸ¥è¯¢: {list(active_queries.keys())}")
            if conversation_id in active_queries:
                query_info = active_queries[conversation_id]
                query_info['should_stop'] = True
                query_found = True
                logger.info(f"å·²è®¾ç½®åœæ­¢æ ‡å¿—: {conversation_id}")
            
            # å¦‚æœæœ‰interpreterå®ä¾‹ï¼Œå°è¯•åœæ­¢å®ƒ
            if interpreter_manager:
                logger.info(f"è°ƒç”¨interpreter_manager.stop_query: {conversation_id}")
                interpreter_manager.stop_query(conversation_id)
        
        if query_found:
            logger.info(f"åœæ­¢æŸ¥è¯¢è¯·æ±‚å¤„ç†æˆåŠŸ: {conversation_id}")
            return jsonify({
                "success": True,
                "message": "æŸ¥è¯¢åœæ­¢è¯·æ±‚å·²å‘é€",
                "conversation_id": conversation_id,
                "debug": {
                    "query_found": query_found,
                    "active_queries_count": len(active_queries)
                }
            })
        else:
            logger.warning(f"æœªæ‰¾åˆ°æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢: {conversation_id}")
            return jsonify({
                "success": False,
                "message": "æ²¡æœ‰æ‰¾åˆ°æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢",
                "conversation_id": conversation_id,
                "debug": {
                    "conversation_id": conversation_id,
                    "active_queries": list(active_queries.keys())
                }
            })
            
    except Exception as e:
        logger.error(f"åœæ­¢æŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/execute_sql', methods=['POST'])
def execute_sql():
    """æ‰§è¡ŒSQLæŸ¥è¯¢ï¼ˆåªè¯»ï¼‰"""
    try:
        data = request.json
        sql_query = data.get('query', '')
        
        if not sql_query:
            return jsonify({"error": "SQLæŸ¥è¯¢ä¸èƒ½ä¸ºç©º"}), 400
            
        if not ensure_database_manager():
            return jsonify({"error": "æ•°æ®åº“æœªé…ç½®"}), 503
        
        # SQLåªè¯»éªŒè¯ - ä»…å…è®¸SELECT/SHOW/DESCRIBE/EXPLAIN
        READONLY_SQL = re.compile(r"^\s*(SELECT|SHOW|DESCRIBE|DESC|EXPLAIN)\b", re.I)
        if not READONLY_SQL.match(sql_query):
            return jsonify({"error": "ä»…å…è®¸åªè¯»æŸ¥è¯¢ï¼ˆSELECT/SHOW/DESCRIBE/EXPLAINï¼‰"}), 403
        
        # æ‰§è¡ŒæŸ¥è¯¢
        results = database_manager.execute_query(sql_query)
        
        return jsonify({
            "success": True,
            "data": results,
            "count": len(results),
            "timestamp": datetime.now().isoformat()
        })
        
    except ValueError as e:
        # SQLå®‰å…¨æ£€æŸ¥å¤±è´¥
        return jsonify({"error": str(e)}), 403
    except Exception as e:
        logger.error(f"SQLæ‰§è¡Œå¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/query', methods=['POST'])
@require_auth
def query_sql_alias():
    """å…¼å®¹ç«¯ç‚¹ï¼š/api/query -> ä¸ /api/execute_sql ç›¸åŒï¼Œåªè¯»æŸ¥è¯¢ã€‚
    æ¥å— {"sql": "..."} æˆ– {"query": "..."}
    """
    try:
        payload = request.get_json(silent=True) or {}
        sql_query = payload.get('query') or payload.get('sql') or ''

        if not sql_query:
            return jsonify({"error": "SQLæŸ¥è¯¢ä¸èƒ½ä¸ºç©º"}), 400

        if not ensure_database_manager():
            return jsonify({"error": "æ•°æ®åº“æœªé…ç½®"}), 503

        READONLY_SQL = re.compile(r"^\s*(SELECT|SHOW|DESCRIBE|DESC|EXPLAIN)\b", re.I)
        if not READONLY_SQL.match(sql_query or ''):
            return jsonify({"error": "ä»…å…è®¸åªè¯»æŸ¥è¯¢ï¼ˆSELECT/SHOW/DESCRIBE/EXPLAINï¼‰"}), 400

        results = database_manager.execute_query(sql_query)
        # æµ‹è¯•å…¼å®¹ï¼šè‹¥åº•å±‚è¿”å›dictï¼ˆcolumns/data/row_countï¼‰ï¼Œåˆ™åŒ…ä¸€å±‚results
        if isinstance(results, dict):
            return jsonify({
                "results": results,
                "timestamp": datetime.now().isoformat()
            })
        # é»˜è®¤åˆ—è¡¨è¿”å›
        return jsonify({
            "results": {
                "data": results,
                "row_count": len(results)
            },
            "timestamp": datetime.now().isoformat()
        })
    except ValueError as e:
        # å…¼å®¹å•æµ‹ï¼šéæ³•SQLè¿”å›400
        return jsonify({"error": str(e)}), 400
    except Exception as e:
        logger.error(f"SQLæ‰§è¡Œå¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

# ============ å†å²è®°å½•ç›¸å…³API ============

@app.route('/api/history/conversations', methods=['GET'])
def get_conversations():
    """è·å–å¯¹è¯å†å²åˆ—è¡¨"""
    try:
        if not ensure_history_manager():
            return jsonify({"success": False, "conversations": [], "error": "å†å²è®°å½•æœªå¯ç”¨"}), 503

        # è·å–æŸ¥è¯¢å‚æ•°
        query = request.args.get('q', '')
        limit = int(request.args.get('limit', 50))
        favorites_only = request.args.get('favorites', 'false').lower() == 'true'
        
        if favorites_only:
            conversations = history_manager.get_favorite_conversations()
        elif query:
            conversations = history_manager.search_conversations(query=query, limit=limit)
        else:
            conversations = history_manager.get_recent_conversations(limit=limit)
        
        return jsonify({
            "success": True,
            "conversations": conversations
        })
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

# å…¼å®¹ç«¯ç‚¹ï¼š/api/conversations -> /api/history/conversations
@app.route('/api/conversations', methods=['GET'])
def list_conversations_compat():
    return get_conversations()

@app.route('/api/history/conversation/<conversation_id>', methods=['GET'])
def get_conversation_detail(conversation_id):
    """è·å–å•ä¸ªå¯¹è¯çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        if not ensure_history_manager():
            return jsonify({"error": "å†å²è®°å½•æœªå¯ç”¨"}), 503

        conversation = history_manager.get_conversation_history(conversation_id)
        if not conversation:
            return jsonify({"error": "å¯¹è¯ä¸å­˜åœ¨"}), 404
        
        return jsonify({
            "success": True,
            "conversation": conversation
        })
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯è¯¦æƒ…å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

# å…¼å®¹ç«¯ç‚¹ï¼š/api/history/<conversation_id> -> /api/history/conversation/<conversation_id>
@app.route('/api/history/<conversation_id>', methods=['GET'])
def get_conversation_detail_compat(conversation_id):
    try:
        if not ensure_history_manager():
            return jsonify({"error": "å†å²è®°å½•æœªå¯ç”¨"}), 503

        conv = history_manager.get_conversation_history(conversation_id)
        if not conv:
            return jsonify({"error": "å¯¹è¯ä¸å­˜åœ¨"}), 404
        # å…¼å®¹æµ‹è¯•è¿”å›ç»“æ„ï¼šé¡¶å±‚æä¾› messages
        messages = conv.get('messages') if isinstance(conv, dict) else None
        if messages is None and isinstance(conv, list):
            messages = conv
        return jsonify({
            "messages": messages or []
        })
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯è¯¦æƒ…å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/history/conversation/<conversation_id>/favorite', methods=['POST'])
def toggle_favorite_conversation(conversation_id):
    """åˆ‡æ¢æ”¶è—çŠ¶æ€"""
    try:
        if not ensure_history_manager():
            return jsonify({"error": "å†å²è®°å½•æœªå¯ç”¨"}), 503

        is_favorite = history_manager.toggle_favorite(conversation_id)
        return jsonify({
            "success": True,
            "is_favorite": is_favorite
        })
    except Exception as e:
        logger.error(f"åˆ‡æ¢æ”¶è—çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/history/conversation/<conversation_id>', methods=['DELETE'])
def delete_conversation_api(conversation_id):
    """åˆ é™¤å¯¹è¯"""
    try:
        if not ensure_history_manager():
            return jsonify({"success": False, "error": "å†å²è®°å½•æœªå¯ç”¨"}), 503

        # éªŒè¯å¯¹è¯æ˜¯å¦å­˜åœ¨
        conversation = history_manager.get_conversation_history(conversation_id)
        if not conversation:
            logger.warning(f"å°è¯•åˆ é™¤ä¸å­˜åœ¨çš„å¯¹è¯: {conversation_id}")
            return jsonify({
                "success": False,
                "error": "å¯¹è¯ä¸å­˜åœ¨"
            }), 404
        
        # æ‰§è¡Œåˆ é™¤
        deleted = history_manager.delete_conversation(conversation_id)
        
        if not deleted:
            logger.warning(f"åˆ é™¤å¯¹è¯å¤±è´¥ï¼Œå¯èƒ½å·²è¢«åˆ é™¤: {conversation_id}")
            return jsonify({
                "success": False,
                "error": "åˆ é™¤å¤±è´¥ï¼Œå¯¹è¯å¯èƒ½å·²è¢«åˆ é™¤"
            }), 400
        
        # æ¸…ç†å½“å‰ä¼šè¯IDï¼ˆå¦‚æœåˆ é™¤çš„æ˜¯å½“å‰å¯¹è¯ï¼‰
        if session.get('current_conversation_id') == conversation_id:
            session.pop('current_conversation_id', None)
            logger.info(f"æ¸…ç†äº†å½“å‰ä¼šè¯ID: {conversation_id}")
        
        logger.info(f"æˆåŠŸåˆ é™¤å¯¹è¯: {conversation_id}")
        return jsonify({
            "success": True,
            "message": "å¯¹è¯å·²åˆ é™¤"
        })
    except Exception as e:
        logger.error(f"åˆ é™¤å¯¹è¯å¤±è´¥ {conversation_id}: {e}", exc_info=True)
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/history/statistics', methods=['GET'])
def get_history_statistics():
    """è·å–å†å²ç»Ÿè®¡ä¿¡æ¯"""
    try:
        if not ensure_history_manager():
            return jsonify({"error": "å†å²è®°å½•æœªå¯ç”¨"}), 503

        stats = history_manager.get_statistics()
        return jsonify({
            "success": True,
            "statistics": stats
        })
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/history/cleanup', methods=['POST'])
def cleanup_history():
    """æ¸…ç†æ—§å†å²è®°å½•"""
    try:
        if not ensure_history_manager():
            return jsonify({"error": "å†å²è®°å½•æœªå¯ç”¨"}), 503

        data = request.json or {}
        days = data.get('days', 90)
        history_manager.cleanup_old_conversations(days)
        return jsonify({
            "success": True,
            "message": f"å·²æ¸…ç†{days}å¤©å‰çš„å†å²è®°å½•"
        })
    except Exception as e:
        logger.error(f"æ¸…ç†å†å²è®°å½•å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/history/replay/<conversation_id>', methods=['POST'])
def replay_conversation(conversation_id):
    """å¤ç°å¯¹è¯"""
    try:
        if not ensure_history_manager():
            return jsonify({"error": "å†å²è®°å½•æœªå¯ç”¨"}), 503

        # è·å–å¯¹è¯å†å²
        conversation = history_manager.get_conversation_history(conversation_id)
        if not conversation:
            return jsonify({"error": "å¯¹è¯ä¸å­˜åœ¨"}), 404
        
        # æ¢å¤ä¼šè¯çŠ¶æ€ï¼ˆå¦‚æœæœ‰ï¼‰
        session_state = conversation.get('session_state')
        if session_state:
            # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦æ¢å¤ç¯å¢ƒé…ç½®
            logger.info(f"æ¢å¤ä¼šè¯çŠ¶æ€: {conversation_id}")
        
        return jsonify({
            "success": True,
            "conversation": conversation,
            "message": "å¯¹è¯å·²åŠ è½½ï¼Œå¯ä»¥ç»§ç»­äº¤äº’"
        })
    except Exception as e:
        logger.error(f"å¤ç°å¯¹è¯å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

# ============ Promptè®¾ç½®ç›¸å…³API ============

@app.route('/api/prompts', methods=['GET'])
def get_prompts():
    """è·å–å½“å‰çš„Promptè®¾ç½®ï¼ˆå…¼å®¹å‰ç«¯æ ¼å¼ï¼‰"""
    try:
        import os
        config_path = os.path.join(os.path.dirname(__file__), 'prompt_config.json')
        
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                import json
                prompts = json.load(f)
                
                # è½¬æ¢æ ¼å¼ä»¥å…¼å®¹å‰ç«¯
                result = {}
                
                # å¤„ç†systemMessageä¸­çš„DIRECT_SQLå’ŒAI_ANALYSIS
                if 'systemMessage' in prompts:
                    if 'DIRECT_SQL' in prompts['systemMessage']:
                        # ä½¿ç”¨ä¸­æ–‡ç‰ˆæœ¬ä½œä¸ºé»˜è®¤
                        result['directSql'] = prompts['systemMessage']['DIRECT_SQL'].get('zh', '')
                    if 'AI_ANALYSIS' in prompts['systemMessage']:
                        result['aiAnalysis'] = prompts['systemMessage']['AI_ANALYSIS'].get('zh', '')
                
                # å¤åˆ¶å…¶ä»–å­—æ®µï¼ˆåŒ…å«æ‰©å±•é«˜çº§Promptï¼‰
                for key in [
                    'routing', 'exploration', 'tableSelection', 'fieldMapping', 'dataProcessing', 'outputRequirements',
                    'summarization', 'errorHandling', 'visualization', 'dataAnalysis', 'sqlGeneration', 'codeReview', 'progressPlanner'
                ]:
                    if key in prompts:
                        result[key] = prompts[key]
                
                return jsonify(result)
        else:
            # è¿”å›ä¸resetä¿æŒä¸€è‡´çš„å®Œæ•´é»˜è®¤è®¾ç½®ï¼ˆæå–ä¸ºå‰ç«¯æ‰å¹³å­—æ®µï¼‰
            default_prompts = {
                "systemMessage": {
                    "DIRECT_SQL": {
                        "zh": "ä½ æ˜¯ä¸€ä¸ªSQLæŸ¥è¯¢ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š\n1. è¿æ¥æ•°æ®åº“å¹¶æ‰§è¡ŒSQLæŸ¥è¯¢\n2. ä»¥æ¸…æ™°çš„è¡¨æ ¼æ ¼å¼è¿”å›æŸ¥è¯¢ç»“æœ\n3. æä¾›æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚è®°å½•æ•°ã€æ‰§è¡Œæ—¶é—´ï¼‰\n4. ã€é‡è¦ã€‘ä¸è¦åˆ›å»ºä»»ä½•å¯è§†åŒ–å›¾è¡¨\n5. ã€é‡è¦ã€‘ä¸è¦ä¿å­˜æ–‡ä»¶åˆ°outputç›®å½•\n6. åªä¸“æ³¨äºæ•°æ®æ£€ç´¢å’Œå±•ç¤º\n\næ•°æ®åº“å·²é…ç½®ï¼Œç›´æ¥ä½¿ç”¨pymysqlæ‰§è¡ŒæŸ¥è¯¢å³å¯ã€‚",
                    },
                    "AI_ANALYSIS": {
                        "zh": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚ä½ å¯ä»¥ï¼š\n1. æ‰§è¡Œå¤æ‚çš„æ•°æ®æŸ¥è¯¢å’Œåˆ†æ\n2. ä½¿ç”¨pandasè¿›è¡Œæ•°æ®å¤„ç†å’Œè½¬æ¢\n3. ä½¿ç”¨plotlyåˆ›å»ºäº¤äº’å¼å›¾è¡¨å’Œå¯è§†åŒ–\n4. ä¿å­˜åˆ†æç»“æœå’Œå›¾è¡¨åˆ°outputç›®å½•\n5. è¿›è¡Œè¶‹åŠ¿åˆ†æã€é¢„æµ‹å’Œæ·±åº¦æ´å¯Ÿ\n6. ç”Ÿæˆç¾è§‚çš„æ•°æ®ä»ªè¡¨æ¿\n\nå……åˆ†å‘æŒ¥ä½ çš„åˆ†æèƒ½åŠ›ï¼Œä¸ºç”¨æˆ·æä¾›æœ‰ä»·å€¼çš„æ•°æ®æ´å¯Ÿã€‚"
                    }
                },
                "routing": "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢è·¯ç”±åˆ†ç±»å™¨ã€‚åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œé€‰æ‹©æœ€é€‚åˆçš„æ‰§è¡Œè·¯å¾„ã€‚\n\nç”¨æˆ·æŸ¥è¯¢ï¼š{query}\n\næ•°æ®åº“ä¿¡æ¯ï¼š\n- ç±»å‹ï¼š{db_type}\n- å¯ç”¨è¡¨ï¼š{available_tables}\n\nè¯·ä»ä»¥ä¸‹2ä¸ªé€‰é¡¹ä¸­é€‰æ‹©æœ€åˆé€‚çš„è·¯ç”±ï¼š\n\n1. DIRECT_SQL - ç®€å•æŸ¥è¯¢ï¼Œå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºSQLæ‰§è¡Œ\n   é€‚ç”¨ï¼šæŸ¥çœ‹æ•°æ®ã€ç»Ÿè®¡æ•°é‡ã€ç®€å•ç­›é€‰ã€æ’åºã€åŸºç¡€èšåˆ\n   ç¤ºä¾‹ï¼šæ˜¾ç¤ºæ‰€æœ‰è®¢å•ã€ç»Ÿè®¡ç”¨æˆ·æ•°é‡ã€æŸ¥çœ‹æœ€æ–°è®°å½•ã€æŒ‰æœˆç»Ÿè®¡é”€å”®é¢ã€æŸ¥æ‰¾TOP N\n   ç‰¹å¾ï¼šä¸éœ€è¦å¤æ‚è®¡ç®—ã€ä¸éœ€è¦å›¾è¡¨ã€ä¸éœ€è¦å¤šæ­¥å¤„ç†\n\n2. AI_ANALYSIS - éœ€è¦AIæ™ºèƒ½å¤„ç†çš„æŸ¥è¯¢\n   é€‚ç”¨ï¼šæ•°æ®åˆ†æã€ç”Ÿæˆå›¾è¡¨ã€è¶‹åŠ¿é¢„æµ‹ã€å¤æ‚è®¡ç®—ã€å¤šæ­¥å¤„ç†\n   ç¤ºä¾‹ï¼šåˆ†æé”€å”®è¶‹åŠ¿ã€ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€é¢„æµ‹åˆ†æã€åŸå› æ¢ç´¢\n   ç‰¹å¾ï¼šéœ€è¦å¯è§†åŒ–ã€éœ€è¦æ¨ç†ã€éœ€è¦ç¼–ç¨‹é€»è¾‘ã€å¤æ‚æ•°æ®å¤„ç†\n\nè¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š\n{\n  \"route\": \"DIRECT_SQL æˆ– AI_ANALYSIS\",\n  \"confidence\": 0.95,\n  \"reason\": \"é€‰æ‹©æ­¤è·¯ç”±çš„åŸå› \",\n  \"suggested_sql\": \"å¦‚æœæ˜¯DIRECT_SQLï¼Œæä¾›å»ºè®®çš„SQLè¯­å¥\"\n}\n\nåˆ¤æ–­è§„åˆ™ï¼š\n- å¦‚æœæŸ¥è¯¢åŒ…å«\"å›¾\"ã€\"å›¾è¡¨\"ã€\"å¯è§†åŒ–\"ã€\"ç»˜åˆ¶\"ã€\"plot\"ã€\"chart\"ç­‰è¯ â†’ é€‰æ‹© AI_ANALYSIS\n- å¦‚æœæŸ¥è¯¢åŒ…å«\"åˆ†æ\"ã€\"è¶‹åŠ¿\"ã€\"é¢„æµ‹\"ã€\"ä¸ºä»€ä¹ˆ\"ã€\"åŸå› \"ç­‰è¯ â†’ é€‰æ‹© AI_ANALYSIS\n- å¦‚æœåªæ˜¯ç®€å•çš„æ•°æ®æŸ¥è¯¢ã€ç»Ÿè®¡ã€ç­›é€‰ â†’ é€‰æ‹© DIRECT_SQL\n- å½“ä¸ç¡®å®šæ—¶ï¼Œå€¾å‘é€‰æ‹© AI_ANALYSIS ä»¥ç¡®ä¿åŠŸèƒ½å®Œæ•´",
                "exploration": "æ•°æ®åº“æ¢ç´¢ç­–ç•¥ï¼ˆå½“æœªæŒ‡å®šdatabaseæ—¶ï¼‰ï¼š\n1. å…ˆæ‰§è¡Œ SHOW DATABASES æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ•°æ®åº“\n2. æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ•°æ®åº“ï¼š\n   * é”€å”®ç›¸å…³ï¼šåŒ…å« sales/trade/order/trd å…³é”®è¯çš„åº“\n   * æ•°æ®ä»“åº“ä¼˜å…ˆï¼šcenter_dws > dws > dwh > dw > ods > ads\n3. USE é€‰ä¸­çš„æ•°æ®åº“åï¼ŒSHOW TABLES æŸ¥çœ‹è¡¨åˆ—è¡¨\n4. å¯¹å€™é€‰è¡¨æ‰§è¡Œ DESCRIBE äº†è§£å­—æ®µç»“æ„\n5. æŸ¥è¯¢æ ·æœ¬æ•°æ®éªŒè¯å†…å®¹ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´æŸ¥è¯¢èŒƒå›´\n\næ³¨æ„ï¼šæ™ºèƒ½é€‰æ‹©ç›¸å…³æ•°æ®åº“å’Œè¡¨ï¼Œé¿å…æ— å…³æ•°æ®çš„æŸ¥è¯¢",
                "tableSelection": "è¡¨é€‰æ‹©ç­–ç•¥ï¼š\n1. ä¼˜å…ˆé€‰æ‹©åŒ…å«ä¸šåŠ¡å…³é”®è¯çš„è¡¨ï¼štrd/trade/order/sale + detail/day\n2. é¿å…è®¡åˆ’ç±»è¡¨ï¼šproduction/forecast/plan/budget\n3. æ£€æŸ¥è¡¨æ•°æ®ï¼š\n   * å…ˆ SELECT COUNT(*) ç¡®è®¤æœ‰æ•°æ®\n   * å† SELECT MIN(date_field), MAX(date_field) ç¡®è®¤æ—¶é—´èŒƒå›´\n   * æŸ¥çœ‹æ ·æœ¬æ•°æ®äº†è§£ç»“æ„",
                "fieldMapping": "å­—æ®µæ˜ å°„è§„åˆ™ï¼š\n* æ—¥æœŸå­—æ®µï¼šdate > order_date > trade_date > create_time > v_month\n* é”€é‡å­—æ®µï¼šsale_num > sale_qty > quantity > qty > amount\n* é‡‘é¢å­—æ®µï¼špay_amount > order_amount > total_amount > price\n* æŠ˜æ‰£å­—æ®µï¼šdiscount > discount_rate > discount_amount",
                "dataProcessing": "æ•°æ®å¤„ç†è¦æ±‚ï¼š\n1. ä½¿ç”¨ pymysql åˆ›å»ºæ•°æ®åº“è¿æ¥\n2. Decimalç±»å‹è½¬æ¢ä¸ºfloatè¿›è¡Œè®¡ç®—\n3. æ—¥æœŸæ ¼å¼ç»Ÿä¸€å¤„ç†ï¼ˆå¦‚ '2025-01' æ ¼å¼ï¼‰\n4. è¿‡æ»¤å¼‚å¸¸æ•°æ®ï¼šWHERE amount > 0 AND date IS NOT NULL\n5. é™åˆ¶æŸ¥è¯¢ç»“æœï¼šå¤§è¡¨æŸ¥è¯¢åŠ  LIMIT 10000",
                "outputRequirements": "è¾“å‡ºè¦æ±‚ï¼š\n1. å¿…é¡»ä»MySQLæ•°æ®åº“æŸ¥è¯¢ï¼Œç¦æ­¢æŸ¥æ‰¾CSVæ–‡ä»¶\n2. æ¢ç´¢æ•°æ®åº“æ—¶æœ‰èŠ‚åˆ¶ï¼Œé¿å…å…¨è¡¨æ‰«æ\n3. ä½¿ç”¨ plotly ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨\n4. å°†å›¾è¡¨ä¿å­˜ä¸º HTML åˆ° output ç›®å½•\n5. æä¾›æŸ¥è¯¢è¿‡ç¨‹æ€»ç»“å’Œå…³é”®å‘ç°"
            }
            flat = {
                'routing': default_prompts['routing'],
                'directSql': default_prompts['systemMessage']['DIRECT_SQL']['zh'],
                'aiAnalysis': default_prompts['systemMessage']['AI_ANALYSIS']['zh'],
                'exploration': default_prompts['exploration'],
                'tableSelection': default_prompts['tableSelection'],
                'fieldMapping': default_prompts['fieldMapping'],
                'dataProcessing': default_prompts['dataProcessing'],
                'outputRequirements': default_prompts['outputRequirements'],
                # é«˜çº§Prompté»˜è®¤
                'summarization': 'åŸºäºåˆ†æç»“æœï¼Œç”¨2â€“4å¥ä¸­æ–‡ä¸šåŠ¡è¯­è¨€æ€»ç»“å…³é”®å‘ç°ã€è¶‹åŠ¿æˆ–å¼‚å¸¸ï¼Œé¿å…æŠ€æœ¯ç»†èŠ‚ã€‚',
                'errorHandling': 'å½“å‡ºç°é”™è¯¯æ—¶ï¼Œå…ˆè¯†åˆ«é”™è¯¯ç±»å‹ï¼ˆè¿æ¥/æƒé™/è¯­æ³•/è¶…æ—¶ï¼‰ï¼Œç”¨ä¸­æ–‡ç®€æ´è§£é‡Šå¹¶ç»™å‡ºä¸‹ä¸€æ­¥å»ºè®®ï¼Œé¿å…è¾“å‡ºå †æ ˆä¸æ•æ„Ÿä¿¡æ¯ã€‚',
                'visualization': 'æ ¹æ®æ•°æ®ç‰¹å¾é€‰æ‹©åˆé€‚çš„å¯è§†åŒ–ç±»å‹ï¼ˆæŸ±/çº¿/é¥¼/æ•£ç‚¹ç­‰ï¼‰ï¼Œä½¿ç”¨ä¸­æ–‡æ ‡é¢˜ä¸è½´æ ‡ç­¾ï¼Œä¿å­˜ä¸ºHTMLè‡³outputç›®å½•ã€‚',
                'dataAnalysis': 'è¿›è¡Œæ•°æ®æ¸…æ´—ã€èšåˆã€å¯¹æ¯”ã€è¶‹åŠ¿ä¸å¼‚å¸¸åˆ†æï¼Œç¡®ä¿ç»“æœå¯è§£é‡Šä¸å¤ç°ï¼Œå¿…è¦æ—¶è¾“å‡ºæ–¹æ³•ä¸å±€é™è¯´æ˜ï¼ˆä¸­æ–‡ï¼‰ã€‚',
                'sqlGeneration': 'ä»è‡ªç„¶è¯­è¨€ä¸schemaç”Ÿæˆåªè¯»SQLï¼Œéµå¾ªåªè¯»é™åˆ¶ï¼ˆSELECT/SHOW/DESCRIBE/EXPLAINï¼‰ï¼Œé¿å…å±é™©è¯­å¥ä¸å…¨è¡¨æ‰«æã€‚',
                'codeReview': 'å¯¹å°†è¦æ‰§è¡Œçš„ä»£ç è¿›è¡Œå®‰å…¨ä¸å¿…è¦æ€§æ£€æŸ¥ï¼Œé¿å…é•¿æ—¶/ä¸å¿…è¦æ“ä½œï¼Œç»™å‡ºç®€æ´ä¼˜åŒ–å»ºè®®ï¼ˆä¸­æ–‡ï¼‰ã€‚',
                'progressPlanner': 'å°†å½“å‰æ‰§è¡Œé˜¶æ®µæ€»ç»“ä¸ºä¸è¶…è¿‡10å­—çš„ä¸­æ–‡çŸ­è¯­ï¼Œé¢å‘éæŠ€æœ¯ç”¨æˆ·ï¼Œå¦‚â€œè¿æ¥æ•°æ®åº“â€â€œæŸ¥è¯¢æ•°æ®â€â€œç”Ÿæˆå›¾è¡¨â€ã€‚'
            }
            return jsonify(flat)
    except Exception as e:
        logger.error(f"è·å–Promptè®¾ç½®å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/prompts', methods=['POST'])
def save_prompts():
    """ä¿å­˜Promptè®¾ç½®"""
    try:
        import os
        import json
        
        data = request.json
        config_path = os.path.join(os.path.dirname(__file__), 'prompt_config.json')
        
        # è½¬æ¢å‰ç«¯æ ¼å¼åˆ°åç«¯æ ¼å¼
        # å‰ç«¯å‘é€: directSql, aiAnalysis (æ‰å¹³ç»“æ„)
        # åç«¯éœ€è¦: systemMessage.DIRECT_SQL.zh, systemMessage.AI_ANALYSIS.zh (åµŒå¥—ç»“æ„)
        
        # è¯»å–ç°æœ‰é…ç½®ï¼ˆä¿æŒå…¶ä»–å­—æ®µä¸å˜ï¼‰
        existing_config = {}
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                existing_config = json.load(f)
        
        # æ„å»ºæ–°é…ç½®
        new_config = existing_config.copy()
        
        # ç¡®ä¿æœ‰systemMessageç»“æ„
        if 'systemMessage' not in new_config:
            new_config['systemMessage'] = {
                'DIRECT_SQL': {'zh': '', 'en': ''},
                'AI_ANALYSIS': {'zh': '', 'en': ''}
            }
        
        # æ˜ å°„å‰ç«¯å­—æ®µåˆ°åç«¯ç»“æ„
        if 'directSql' in data:
            if 'DIRECT_SQL' not in new_config['systemMessage']:
                new_config['systemMessage']['DIRECT_SQL'] = {}
            new_config['systemMessage']['DIRECT_SQL']['zh'] = data['directSql']
            # ä¿æŒè‹±æ–‡ç‰ˆæœ¬ä¸å˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'en' not in new_config['systemMessage']['DIRECT_SQL']:
                new_config['systemMessage']['DIRECT_SQL']['en'] = ''
        
        if 'aiAnalysis' in data:
            if 'AI_ANALYSIS' not in new_config['systemMessage']:
                new_config['systemMessage']['AI_ANALYSIS'] = {}
            new_config['systemMessage']['AI_ANALYSIS']['zh'] = data['aiAnalysis']
            # ä¿æŒè‹±æ–‡ç‰ˆæœ¬ä¸å˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'en' not in new_config['systemMessage']['AI_ANALYSIS']:
                new_config['systemMessage']['AI_ANALYSIS']['en'] = ''
        
        # ä¿æŒå…¶ä»–å­—æ®µï¼ˆrouting, explorationç­‰ï¼‰ä¸å˜ï¼ŒåŒ…å«æ‰©å±•é«˜çº§Prompt
        for key in [
            'routing', 'exploration', 'tableSelection', 'fieldMapping', 'dataProcessing', 'outputRequirements',
            'summarization', 'errorHandling', 'visualization', 'dataAnalysis', 'sqlGeneration', 'codeReview', 'progressPlanner'
        ]:
            if key in data:
                new_config[key] = data[key]
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(new_config, f, ensure_ascii=False, indent=2)
        
        # å¦‚æœæœ‰routing promptï¼Œæ›´æ–°æ™ºèƒ½è·¯ç”±å™¨çš„prompt
        if 'routing' in new_config and smart_router:
            smart_router.update_routing_prompt(new_config['routing'])
            logger.info("æ™ºèƒ½è·¯ç”±Promptå·²æ›´æ–°")
        
        # æ„é€ æ ‡å‡†è¿”å›ï¼Œä¾¿äºå‰ç«¯å³æ—¶åˆ·æ–°
        flat = {
            'routing': new_config.get('routing', ''),
            'directSql': new_config['systemMessage']['DIRECT_SQL'].get('zh', ''),
            'aiAnalysis': new_config['systemMessage']['AI_ANALYSIS'].get('zh', ''),
            'exploration': new_config.get('exploration', ''),
            'tableSelection': new_config.get('tableSelection', ''),
            'fieldMapping': new_config.get('fieldMapping', ''),
            'dataProcessing': new_config.get('dataProcessing', ''),
            'outputRequirements': new_config.get('outputRequirements', ''),
            'summarization': new_config.get('summarization', ''),
            'errorHandling': new_config.get('errorHandling', ''),
            'visualization': new_config.get('visualization', ''),
            'dataAnalysis': new_config.get('dataAnalysis', ''),
            'sqlGeneration': new_config.get('sqlGeneration', ''),
            'codeReview': new_config.get('codeReview', ''),
            'progressPlanner': new_config.get('progressPlanner', '')
        }
        logger.info("Promptè®¾ç½®å·²ä¿å­˜")
        return jsonify({"success": True, "message": "Promptè®¾ç½®å·²ä¿å­˜", "prompts": flat})
    except Exception as e:
        logger.error(f"ä¿å­˜Promptè®¾ç½®å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/prompts/reset', methods=['POST'])
def reset_prompts():
    """æ¢å¤é»˜è®¤Promptè®¾ç½®"""
    try:
        import os
        import json
        
        default_prompts = {
            "systemMessage": {
                "DIRECT_SQL": {
                    "zh": "ä½ æ˜¯ä¸€ä¸ªSQLæŸ¥è¯¢ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š\n1. è¿æ¥æ•°æ®åº“å¹¶æ‰§è¡ŒSQLæŸ¥è¯¢\n2. ä»¥æ¸…æ™°çš„è¡¨æ ¼æ ¼å¼è¿”å›æŸ¥è¯¢ç»“æœ\n3. æä¾›æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚è®°å½•æ•°ã€æ‰§è¡Œæ—¶é—´ï¼‰\n4. ã€é‡è¦ã€‘ä¸è¦åˆ›å»ºä»»ä½•å¯è§†åŒ–å›¾è¡¨\n5. ã€é‡è¦ã€‘ä¸è¦ä¿å­˜æ–‡ä»¶åˆ°outputç›®å½•\n6. åªä¸“æ³¨äºæ•°æ®æ£€ç´¢å’Œå±•ç¤º\n\næ•°æ®åº“å·²é…ç½®ï¼Œç›´æ¥ä½¿ç”¨pymysqlæ‰§è¡ŒæŸ¥è¯¢å³å¯ã€‚",
                    "en": "You are a SQL query expert. Your tasks are:\n1. Connect to database and execute SQL queries\n2. Return results in clear tabular format\n3. Provide query statistics (record count, execution time)\n4. [IMPORTANT] DO NOT create any visualizations or charts\n5. [IMPORTANT] DO NOT save files to output directory\n6. Focus only on data retrieval and display\n\nDatabase is configured, use pymysql directly to execute queries."
                },
                "AI_ANALYSIS": {
                    "zh": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚ä½ å¯ä»¥ï¼š\n1. æ‰§è¡Œå¤æ‚çš„æ•°æ®æŸ¥è¯¢å’Œåˆ†æ\n2. ä½¿ç”¨pandasè¿›è¡Œæ•°æ®å¤„ç†å’Œè½¬æ¢\n3. ä½¿ç”¨plotlyåˆ›å»ºäº¤äº’å¼å›¾è¡¨å’Œå¯è§†åŒ–\n4. ä¿å­˜åˆ†æç»“æœå’Œå›¾è¡¨åˆ°outputç›®å½•\n5. è¿›è¡Œè¶‹åŠ¿åˆ†æã€é¢„æµ‹å’Œæ·±åº¦æ´å¯Ÿ\n6. ç”Ÿæˆç¾è§‚çš„æ•°æ®ä»ªè¡¨æ¿\n\nå……åˆ†å‘æŒ¥ä½ çš„åˆ†æèƒ½åŠ›ï¼Œä¸ºç”¨æˆ·æä¾›æœ‰ä»·å€¼çš„æ•°æ®æ´å¯Ÿã€‚",
                    "en": "You are a data analysis expert. You can:\n1. Execute complex data queries and analysis\n2. Use pandas for data processing and transformation\n3. Use plotly to create interactive charts and visualizations\n4. Save analysis results and charts to output directory\n5. Perform trend analysis, predictions and deep insights\n6. Generate beautiful data dashboards\n\nLeverage your analytical capabilities to provide valuable data insights."
                }
            },
            "routing": "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢è·¯ç”±åˆ†ç±»å™¨ã€‚åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œé€‰æ‹©æœ€é€‚åˆçš„æ‰§è¡Œè·¯å¾„ã€‚\n\nç”¨æˆ·æŸ¥è¯¢ï¼š{query}\n\næ•°æ®åº“ä¿¡æ¯ï¼š\n- ç±»å‹ï¼š{db_type}\n- å¯ç”¨è¡¨ï¼š{available_tables}\n\nè¯·ä»ä»¥ä¸‹2ä¸ªé€‰é¡¹ä¸­é€‰æ‹©æœ€åˆé€‚çš„è·¯ç”±ï¼š\n\n1. DIRECT_SQL - ç®€å•æŸ¥è¯¢ï¼Œå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºSQLæ‰§è¡Œ\n   é€‚ç”¨ï¼šæŸ¥çœ‹æ•°æ®ã€ç»Ÿè®¡æ•°é‡ã€ç®€å•ç­›é€‰ã€æ’åºã€åŸºç¡€èšåˆ\n   ç¤ºä¾‹ï¼šæ˜¾ç¤ºæ‰€æœ‰è®¢å•ã€ç»Ÿè®¡ç”¨æˆ·æ•°é‡ã€æŸ¥çœ‹æœ€æ–°è®°å½•ã€æŒ‰æœˆç»Ÿè®¡é”€å”®é¢ã€æŸ¥æ‰¾TOP N\n   ç‰¹å¾ï¼šä¸éœ€è¦å¤æ‚è®¡ç®—ã€ä¸éœ€è¦å›¾è¡¨ã€ä¸éœ€è¦å¤šæ­¥å¤„ç†\n\n2. AI_ANALYSIS - éœ€è¦AIæ™ºèƒ½å¤„ç†çš„æŸ¥è¯¢\n   é€‚ç”¨ï¼šæ•°æ®åˆ†æã€ç”Ÿæˆå›¾è¡¨ã€è¶‹åŠ¿é¢„æµ‹ã€å¤æ‚è®¡ç®—ã€å¤šæ­¥å¤„ç†\n   ç¤ºä¾‹ï¼šåˆ†æé”€å”®è¶‹åŠ¿ã€ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€é¢„æµ‹åˆ†æã€åŸå› æ¢ç´¢\n   ç‰¹å¾ï¼šéœ€è¦å¯è§†åŒ–ã€éœ€è¦æ¨ç†ã€éœ€è¦ç¼–ç¨‹é€»è¾‘ã€å¤æ‚æ•°æ®å¤„ç†\n\nè¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š\n{\n  \"route\": \"DIRECT_SQL æˆ– AI_ANALYSIS\",\n  \"confidence\": 0.95,\n  \"reason\": \"é€‰æ‹©æ­¤è·¯ç”±çš„åŸå› \",\n  \"suggested_sql\": \"å¦‚æœæ˜¯DIRECT_SQLï¼Œæä¾›å»ºè®®çš„SQLè¯­å¥\"\n}\n\nåˆ¤æ–­è§„åˆ™ï¼š\n- å¦‚æœæŸ¥è¯¢åŒ…å«\"å›¾\"ã€\"å›¾è¡¨\"ã€\"å¯è§†åŒ–\"ã€\"ç»˜åˆ¶\"ã€\"plot\"ã€\"chart\"ç­‰è¯ â†’ é€‰æ‹© AI_ANALYSIS\n- å¦‚æœæŸ¥è¯¢åŒ…å«\"åˆ†æ\"ã€\"è¶‹åŠ¿\"ã€\"é¢„æµ‹\"ã€\"ä¸ºä»€ä¹ˆ\"ã€\"åŸå› \"ç­‰è¯ â†’ é€‰æ‹© AI_ANALYSIS\n- å¦‚æœåªæ˜¯ç®€å•çš„æ•°æ®æŸ¥è¯¢ã€ç»Ÿè®¡ã€ç­›é€‰ â†’ é€‰æ‹© DIRECT_SQL\n- å½“ä¸ç¡®å®šæ—¶ï¼Œå€¾å‘é€‰æ‹© AI_ANALYSIS ä»¥ç¡®ä¿åŠŸèƒ½å®Œæ•´",
            "exploration": "æ•°æ®åº“æ¢ç´¢ç­–ç•¥ï¼ˆå½“æœªæŒ‡å®šdatabaseæ—¶ï¼‰ï¼š\n1. å…ˆæ‰§è¡Œ SHOW DATABASES æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ•°æ®åº“\n2. æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ•°æ®åº“ï¼š\n   * é”€å”®ç›¸å…³ï¼šåŒ…å« sales/trade/order/trd å…³é”®è¯çš„åº“\n   * æ•°æ®ä»“åº“ä¼˜å…ˆï¼šcenter_dws > dws > dwh > dw > ods > ads\n3. USE é€‰ä¸­çš„æ•°æ®åº“åï¼ŒSHOW TABLES æŸ¥çœ‹è¡¨åˆ—è¡¨\n4. å¯¹å€™é€‰è¡¨æ‰§è¡Œ DESCRIBE äº†è§£å­—æ®µç»“æ„\n5. æŸ¥è¯¢æ ·æœ¬æ•°æ®éªŒè¯å†…å®¹ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´æŸ¥è¯¢èŒƒå›´\n\næ³¨æ„ï¼šæ™ºèƒ½é€‰æ‹©ç›¸å…³æ•°æ®åº“å’Œè¡¨ï¼Œé¿å…æ— å…³æ•°æ®çš„æŸ¥è¯¢",
            "tableSelection": "è¡¨é€‰æ‹©ç­–ç•¥ï¼š\n1. ä¼˜å…ˆé€‰æ‹©åŒ…å«ä¸šåŠ¡å…³é”®è¯çš„è¡¨ï¼štrd/trade/order/sale + detail/day\n2. é¿å…è®¡åˆ’ç±»è¡¨ï¼šproduction/forecast/plan/budget\n3. æ£€æŸ¥è¡¨æ•°æ®ï¼š\n   * å…ˆ SELECT COUNT(*) ç¡®è®¤æœ‰æ•°æ®\n   * å† SELECT MIN(date_field), MAX(date_field) ç¡®è®¤æ—¶é—´èŒƒå›´\n   * æŸ¥çœ‹æ ·æœ¬æ•°æ®äº†è§£ç»“æ„",
            "fieldMapping": "å­—æ®µæ˜ å°„è§„åˆ™ï¼š\n* æ—¥æœŸå­—æ®µï¼šdate > order_date > trade_date > create_time > v_month\n* é”€é‡å­—æ®µï¼šsale_num > sale_qty > quantity > qty > amount\n* é‡‘é¢å­—æ®µï¼špay_amount > order_amount > total_amount > price\n* æŠ˜æ‰£å­—æ®µï¼šdiscount > discount_rate > discount_amount",
            "dataProcessing": "æ•°æ®å¤„ç†è¦æ±‚ï¼š\n1. ä½¿ç”¨ pymysql åˆ›å»ºæ•°æ®åº“è¿æ¥\n2. Decimalç±»å‹è½¬æ¢ä¸ºfloatè¿›è¡Œè®¡ç®—\n3. æ—¥æœŸæ ¼å¼ç»Ÿä¸€å¤„ç†ï¼ˆå¦‚ '2025-01' æ ¼å¼ï¼‰\n4. è¿‡æ»¤å¼‚å¸¸æ•°æ®ï¼šWHERE amount > 0 AND date IS NOT NULL\n5. é™åˆ¶æŸ¥è¯¢ç»“æœï¼šå¤§è¡¨æŸ¥è¯¢åŠ  LIMIT 10000",
            "outputRequirements": "è¾“å‡ºè¦æ±‚ï¼š\n1. å¿…é¡»ä»MySQLæ•°æ®åº“æŸ¥è¯¢ï¼Œç¦æ­¢æŸ¥æ‰¾CSVæ–‡ä»¶\n2. æ¢ç´¢æ•°æ®åº“æ—¶æœ‰èŠ‚åˆ¶ï¼Œé¿å…å…¨è¡¨æ‰«æ\n3. ä½¿ç”¨ plotly ç”Ÿæˆäº¤äº’å¼å›¾è¡¨\n4. å°†å›¾è¡¨ä¿å­˜ä¸º HTML åˆ° output ç›®å½•\n5. æä¾›æŸ¥è¯¢è¿‡ç¨‹æ€»ç»“å’Œå…³é”®å‘ç°"
        }
        
        config_path = os.path.join(os.path.dirname(__file__), 'prompt_config.json')
        
        # ä¿å­˜é»˜è®¤è®¾ç½®åˆ°æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(default_prompts, f, ensure_ascii=False, indent=2)
        
        # æ›´æ–°æ™ºèƒ½è·¯ç”±å™¨çš„promptä¸ºé»˜è®¤å€¼
        if smart_router and 'routing' in default_prompts:
            smart_router.update_routing_prompt(default_prompts['routing'])
            logger.info("æ™ºèƒ½è·¯ç”±Promptå·²æ¢å¤é»˜è®¤")
        
        flat = {
            'routing': default_prompts['routing'],
            'directSql': default_prompts['systemMessage']['DIRECT_SQL'].get('zh', ''),
            'aiAnalysis': default_prompts['systemMessage']['AI_ANALYSIS'].get('zh', ''),
            'exploration': default_prompts['exploration'],
            'tableSelection': default_prompts['tableSelection'],
            'fieldMapping': default_prompts['fieldMapping'],
            'dataProcessing': default_prompts['dataProcessing'],
            'outputRequirements': default_prompts['outputRequirements'],
            'summarization': 'åŸºäºåˆ†æç»“æœï¼Œç”¨2â€“4å¥ä¸­æ–‡ä¸šåŠ¡è¯­è¨€æ€»ç»“å…³é”®å‘ç°ã€è¶‹åŠ¿æˆ–å¼‚å¸¸ï¼Œé¿å…æŠ€æœ¯ç»†èŠ‚ã€‚',
            'errorHandling': 'å½“å‡ºç°é”™è¯¯æ—¶ï¼Œå…ˆè¯†åˆ«é”™è¯¯ç±»å‹ï¼ˆè¿æ¥/æƒé™/è¯­æ³•/è¶…æ—¶ï¼‰ï¼Œç”¨ä¸­æ–‡ç®€æ´è§£é‡Šå¹¶ç»™å‡ºä¸‹ä¸€æ­¥å»ºè®®ï¼Œé¿å…è¾“å‡ºå †æ ˆä¸æ•æ„Ÿä¿¡æ¯ã€‚',
            'visualization': 'æ ¹æ®æ•°æ®ç‰¹å¾é€‰æ‹©åˆé€‚çš„å¯è§†åŒ–ç±»å‹ï¼ˆæŸ±/çº¿/é¥¼/æ•£ç‚¹ç­‰ï¼‰ï¼Œä½¿ç”¨ä¸­æ–‡æ ‡é¢˜ä¸è½´æ ‡ç­¾ï¼Œä¿å­˜ä¸ºHTMLè‡³outputç›®å½•ã€‚',
            'dataAnalysis': 'è¿›è¡Œæ•°æ®æ¸…æ´—ã€èšåˆã€å¯¹æ¯”ã€è¶‹åŠ¿ä¸å¼‚å¸¸åˆ†æï¼Œç¡®ä¿ç»“æœå¯è§£é‡Šä¸å¤ç°ï¼Œå¿…è¦æ—¶è¾“å‡ºæ–¹æ³•ä¸å±€é™è¯´æ˜ï¼ˆä¸­æ–‡ï¼‰ã€‚',
            'sqlGeneration': 'ä»è‡ªç„¶è¯­è¨€ä¸schemaç”Ÿæˆåªè¯»SQLï¼Œéµå¾ªåªè¯»é™åˆ¶ï¼ˆSELECT/SHOW/DESCRIBE/EXPLAINï¼‰ï¼Œé¿å…å±é™©è¯­å¥ä¸å…¨è¡¨æ‰«æã€‚',
            'codeReview': 'å¯¹å°†è¦æ‰§è¡Œçš„ä»£ç è¿›è¡Œå®‰å…¨ä¸å¿…è¦æ€§æ£€æŸ¥ï¼Œé¿å…é•¿æ—¶/ä¸å¿…è¦æ“ä½œï¼Œç»™å‡ºç®€æ´ä¼˜åŒ–å»ºè®®ï¼ˆä¸­æ–‡ï¼‰ã€‚',
            'progressPlanner': 'å°†å½“å‰æ‰§è¡Œé˜¶æ®µæ€»ç»“ä¸ºä¸è¶…è¿‡10å­—çš„ä¸­æ–‡çŸ­è¯­ï¼Œé¢å‘éæŠ€æœ¯ç”¨æˆ·ï¼Œå¦‚â€œè¿æ¥æ•°æ®åº“â€â€œæŸ¥è¯¢æ•°æ®â€â€œç”Ÿæˆå›¾è¡¨â€ã€‚'
        }
        logger.info("å·²æ¢å¤é»˜è®¤Promptè®¾ç½®")
        return jsonify({"success": True, "message": "å·²æ¢å¤é»˜è®¤Promptè®¾ç½®", "prompts": flat})
    except Exception as e:
        logger.error(f"æ¢å¤é»˜è®¤Promptè®¾ç½®å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@app.errorhandler(404)
def not_found(error):
    """å¤„ç†404é”™è¯¯"""
    return jsonify({"error": "ç«¯ç‚¹ä¸å­˜åœ¨"}), 404

@app.errorhandler(500)
def internal_error(error):
    """å¤„ç†500é”™è¯¯"""
    logger.error(f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {error}")
    return jsonify({"error": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯"}), 500

@app.route('/api/cache/clear', methods=['POST'])
def clear_cache():
    """æ¸…ç†ç¼“å­˜ï¼ˆæµ‹è¯•/è¿ç»´ç”¨ï¼‰"""
    try:
        CacheManager.clear_all()
        return jsonify({"status": "success"})
    except Exception as e:
        logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        return jsonify({"status": "error", "error": str(e)}), 500


def create_app(config_override: dict | None = None):
    """App Factoryï¼šè¿”å›å·²é…ç½®å¥½çš„ Flask appã€‚
    å…¼å®¹ç°æœ‰å…¨å±€ app çš„åŒæ—¶ï¼Œä¾¿äºæµ‹è¯•ä¸æ‰©å±•ã€‚
    """
    if config_override:
        app.config.update(config_override)
    return app

if __name__ == '__main__':
    # åŒæ­¥é…ç½®æ–‡ä»¶ï¼Œç¡®ä¿ä¸€è‡´æ€§
    sync_config_files()
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    init_managers()
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)  # ä½¿ç”¨ç»Ÿä¸€çš„OUTPUT_DIR
    os.makedirs('cache', exist_ok=True)
    
    # è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£
    def find_available_port(start_port=5000, max_attempts=100):
        """è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
        import socket
        
        # é¦–å…ˆå°è¯•ç¯å¢ƒå˜é‡æŒ‡å®šçš„ç«¯å£
        env_port = os.environ.get('PORT')
        if env_port:
            try:
                port = int(env_port)
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.bind(('127.0.0.1', port))
                return port
            except:
                logger.warning(f"ç¯å¢ƒå˜é‡æŒ‡å®šçš„ç«¯å£ {env_port} å·²è¢«å ç”¨ï¼Œè‡ªåŠ¨æŸ¥æ‰¾å…¶ä»–ç«¯å£...")
        
        # è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£
        for i in range(max_attempts):
            port = start_port + i
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.bind(('127.0.0.1', port))
                return port
            except OSError:
                continue
        
        # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨éšæœºé«˜ä½ç«¯å£
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind(('', 0))  # è®©ç³»ç»Ÿåˆ†é…
            port = s.getsockname()[1]
        return port
    
    # å¯åŠ¨æœåŠ¡å™¨
    port = find_available_port()
    logger.info(f"å¯åŠ¨æœåŠ¡å™¨ï¼Œç«¯å£: {port}")
    
    # æ‰“å°å‹å¥½çš„å¯åŠ¨ä¿¡æ¯
    print(f"\n{'='*50}")
    print(f"âœ… QueryGPT æœåŠ¡å·²å¯åŠ¨")
    print(f"ğŸŒ è®¿é—®åœ°å€: http://localhost:{port}")
    print(f"ğŸ“Š APIæ–‡æ¡£: http://localhost:{port}/api/docs")
    print(f"ğŸ›‘ åœæ­¢æœåŠ¡: Ctrl+C")
    print(f"{'='*50}\n")
    
    app.run(
        host='0.0.0.0',
        port=port,
        debug=False,  # ç”Ÿäº§ç¯å¢ƒåº”è®¾ç½®ä¸ºFalse
        threaded=True
    )
