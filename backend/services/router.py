"""
AIé©±åŠ¨çš„æ™ºèƒ½æŸ¥è¯¢è·¯ç”±ç³»ç»Ÿ
å®Œå…¨ä½¿ç”¨AIè¿›è¡ŒæŸ¥è¯¢åˆ†ç±»å’Œè·¯ç”±å†³ç­–
"""
import logging
import time
from typing import Dict, Any, Optional
from backend.ai_router import AIRoutingClassifier, RouteType
from backend.services.llm import llm_manager
from backend.core.config import ConfigLoader
from backend.services.guard import DatabaseGuard, build_guard_block_payload

logger = logging.getLogger(__name__)

class SmartRouter:
    """
    æ™ºèƒ½è·¯ç”±å™¨
    ä½¿ç”¨AIåˆ¤æ–­æŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æœ€ä¼˜æ‰§è¡Œè·¯å¾„
    """
    
    def __init__(self, database_manager=None, interpreter_manager=None, database_guard: DatabaseGuard | None = None):
        """
        åˆå§‹åŒ–æ™ºèƒ½è·¯ç”±å™¨
        
        Args:
            database_manager: æ•°æ®åº“ç®¡ç†å™¨
            interpreter_manager: OpenInterpreterç®¡ç†å™¨
        """
        self.database_manager = database_manager
        self.database_guard = database_guard or DatabaseGuard(database_manager)
        self.interpreter_manager = interpreter_manager
        
        # åŠ è½½ä¿å­˜çš„routing prompt
        custom_prompt = self._load_routing_prompt()

        # è¯»å–ç‰¹æ€§å¼€å…³ï¼Œé¿å…ç¼ºçœé…ç½®è§¦å‘å¼‚å¸¸
        self.feature_flags = self._load_feature_flags()
        
        # åˆå§‹åŒ–AIåˆ†ç±»å™¨å¹¶è¿›è¡Œå¥åº·æ£€æŸ¥
        self.llm_available = False
        try:
            llm_service = llm_manager.get_service()
            
            # æ›´è¯¦ç»†çš„å¥åº·æ£€æŸ¥
            if llm_service and llm_service.api_key:
                # å°è¯•ä¸€ä¸ªç®€å•çš„æµ‹è¯•è°ƒç”¨
                test_success = self._test_llm_service(llm_service)
                
                if test_success:
                    self.ai_classifier = AIRoutingClassifier(llm_service, custom_prompt)
                    self.llm_available = True
                    logger.info("âœ… æ™ºèƒ½è·¯ç”±AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸå¹¶é€šè¿‡å¥åº·æ£€æŸ¥")
                else:
                    self.ai_classifier = AIRoutingClassifier(None, custom_prompt)
                    logger.warning("âš ï¸ LLMæœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸºäºè§„åˆ™çš„è·¯ç”±")
            else:
                self.ai_classifier = AIRoutingClassifier(None, custom_prompt)
                logger.warning("âš ï¸ æ™ºèƒ½è·¯ç”±: LLMæœåŠ¡é…ç½®ç¼ºå¤±ï¼Œå°†ä½¿ç”¨åŸºäºè§„åˆ™çš„è·¯ç”±")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–AIåˆ†ç±»å™¨å¤±è´¥: {e}")
            self.ai_classifier = AIRoutingClassifier(None, custom_prompt)
        
        # è·¯ç”±ç»Ÿè®¡ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self.routing_stats = {
            "total_queries": 0,
            "qa_queries": 0,
            "analysis_queries": 0,
            "aborted_queries": 0,
            "ai_classification_time": 0,
            "total_time_saved": 0.0,
            "fallback_count": 0,
            "rule_based_routes": 0,
            "forced_queries": 0
        }
    
    def _load_feature_flags(self) -> Dict[str, Any]:
        """åŠ è½½æœ€æ–°çš„åŠŸèƒ½å¼€å…³é…ç½®"""
        try:
            config = ConfigLoader.get_config()
            features = config.get('features') or {}
            if not isinstance(features, dict):
                return {}
            return features
        except Exception as exc:
            logger.debug("åŠ è½½åŠŸèƒ½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: %s", exc)
            return {}
    
    def _test_llm_service(self, llm_service) -> bool:
        """æµ‹è¯•LLMæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            # ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å complete è€Œä¸æ˜¯ query
            test_response = llm_service.complete(
                prompt="Hi, this is a test. Please respond with 'OK'.",
                max_tokens=10
            )
            return test_response is not None and len(str(test_response)) > 0
        except Exception as e:
            logger.error(f"LLMæœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _rule_based_classify(self, query: str) -> Dict[str, Any]:
        """åŸºäºè§„åˆ™çš„æŸ¥è¯¢åˆ†ç±»ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        query_lower = query.lower()
        
        # å…³é”®è¯æ£€æµ‹è§„åˆ™
        visualization_keywords = ['å›¾', 'å›¾è¡¨', 'å¯è§†åŒ–', 'ç»˜åˆ¶', 'plot', 'chart', 'graph', 'è¶‹åŠ¿å›¾', 'é¥¼å›¾', 'æŸ±çŠ¶å›¾']
        analysis_keywords = ['åˆ†æ', 'è¶‹åŠ¿', 'é¢„æµ‹', 'ä¸ºä»€ä¹ˆ', 'åŸå› ', 'æ¯”è¾ƒ', 'å¯¹æ¯”', 'è¯„ä¼°', 'æ´å¯Ÿ']
        complex_keywords = ['è®¡ç®—', 'ç»Ÿè®¡åˆ†æ', 'ç›¸å…³æ€§', 'å›å½’', 'èšç±»', 'æœºå™¨å­¦ä¹ ']
        simple_keywords = ['æ˜¾ç¤º', 'æŸ¥çœ‹', 'åˆ—å‡º', 'show', 'select', 'æŸ¥è¯¢', 'ç»Ÿè®¡', 'æ•°é‡', 'æ€»æ•°']
        chit_chat_keywords = ['ä½ å¥½', 'è°¢è°¢', 'ä½ æ˜¯è°', 'èŠèŠ', 'è®²ä¸ª', 'æ•…äº‹', 'ç¬‘è¯', 'å¤©æ°”', 'æœºå™¨äºº']
        
        # æ£€æµ‹æŸ¥è¯¢ç±»å‹
        has_visualization = any(keyword in query_lower for keyword in visualization_keywords)
        has_analysis = any(keyword in query_lower for keyword in analysis_keywords)
        has_complex = any(keyword in query_lower for keyword in complex_keywords)
        has_simple = any(keyword in query_lower for keyword in simple_keywords)
        is_chit_chat = any(keyword in query_lower for keyword in chit_chat_keywords)
        
        # å†³ç­–é€»è¾‘
        if is_chit_chat and not (has_simple or has_analysis or has_visualization):
            return {
                'route': RouteType.QA.value,
                'confidence': 0.55,
                'reason': 'ç–‘ä¼¼é—²èŠ/éæ•°æ®åº“é—®é¢˜',
                'method': 'rule_based'
            }
        if has_visualization or has_complex:
            return {
                'route': RouteType.ANALYSIS.value,
                'confidence': 0.8,
                'reason': f'æŸ¥è¯¢åŒ…å«{"å¯è§†åŒ–" if has_visualization else "å¤æ‚åˆ†æ"}éœ€æ±‚',
                'method': 'rule_based'
            }
        if has_analysis:
            return {
                'route': RouteType.ANALYSIS.value,
                'confidence': 0.7,
                'reason': 'æŸ¥è¯¢éœ€è¦æ•°æ®åˆ†æ',
                'method': 'rule_based'
            }
        if has_simple and not has_visualization and not has_analysis:
            return {
                'route': RouteType.ANALYSIS.value,
                'confidence': 0.6,
                'reason': 'æ£€æµ‹åˆ°å–æ•°éœ€æ±‚ï¼Œäº¤ç”±åˆ†ææµç¨‹å¤„ç†',
                'method': 'rule_based'
            }
        # é»˜è®¤ï¼šå¦‚æœé—®é¢˜ä»¥é—®å·ç»“æŸæˆ–æ˜æ˜¾å¯¹è¯ï¼Œèµ°QAï¼Œå¦åˆ™èµ°åˆ†æ
        if query.strip().endswith('ï¼Ÿ') or query.strip().endswith('?'):
            return {
                'route': RouteType.QA.value,
                'confidence': 0.5,
                'reason': 'æ— æ³•è¯†åˆ«æ•°æ®éœ€æ±‚ï¼Œå»ºè®®å…ˆæ¾„æ¸…',
                'method': 'rule_based'
            }
        return {
            'route': RouteType.ANALYSIS.value,
            'confidence': 0.5,
            'reason': 'é»˜è®¤ä½¿ç”¨åˆ†æè·¯ç”±ç¡®ä¿åŠŸèƒ½å®Œæ•´',
            'method': 'rule_based'
        }
    
    def route(self, query: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ™ºèƒ½è·¯ç”±æŸ¥è¯¢åˆ°æœ€ä¼˜æ‰§è¡Œè·¯å¾„
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: æŸ¥è¯¢ä¸Šä¸‹æ–‡
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        start_time = time.time()
        # æ¯æ¬¡è·¯ç”±å‰åˆ·æ–°åŠŸèƒ½é…ç½®ï¼Œç¡®ä¿å‰ç«¯ä¿®æ”¹å³æ—¶ç”Ÿæ•ˆ
        self.feature_flags = self._load_feature_flags()
        feature_flags = self.feature_flags or {}

        # æ‹·è´ä¸Šä¸‹æ–‡ï¼Œé¿å…ä¿®æ”¹åŸå§‹å¯¹è±¡
        context = dict(context or {})
        language = context.get('language', 'zh') or 'zh'
        context.setdefault('language', language)
        self.routing_stats["total_queries"] += 1
        
        try:
            # å‡†å¤‡è·¯ç”±ä¸Šä¸‹æ–‡
            routing_context = self._prepare_routing_context(context)
            
            # å†³å®šä½¿ç”¨å“ªç§åˆ†ç±»æ–¹æ³•
            if self.llm_available and self.ai_classifier.llm_service:
                # ä½¿ç”¨AIè¿›è¡Œåˆ†ç±»
                logger.debug("ä½¿ç”¨AIåˆ†ç±»å™¨è¿›è¡Œè·¯ç”±å†³ç­–")
                classification = self.ai_classifier.classify(query, routing_context)
                route_type = classification.get('route', RouteType.ANALYSIS.value)
                confidence = classification.get('confidence', 0.5)
                method = classification.get('method', 'ai')
                
                # å¦‚æœAIåˆ†ç±»ç½®ä¿¡åº¦å¤ªä½ï¼Œä½¿ç”¨è§„åˆ™è¡¥å……
                if confidence < 0.5:
                    logger.info(f"AIåˆ†ç±»ç½®ä¿¡åº¦è¾ƒä½({confidence:.2f})ï¼Œä½¿ç”¨è§„åˆ™è·¯ç”±è¡¥å……")
                    rule_classification = self._rule_based_classify(query)
                    
                    # å¦‚æœè§„åˆ™è·¯ç”±ç½®ä¿¡åº¦æ›´é«˜ï¼Œä½¿ç”¨è§„åˆ™è·¯ç”±
                    if rule_classification['confidence'] > confidence:
                        classification = rule_classification
                        route_type = classification['route']
                        confidence = classification['confidence']
                        method = 'rule_based_override'
                        self.routing_stats["rule_based_routes"] += 1
            else:
                # LLMä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†ç±»
                logger.info("LLMæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„è·¯ç”±")
                classification = self._rule_based_classify(query)
                route_type = classification.get('route', RouteType.ANALYSIS.value)
                confidence = classification.get('confidence', 0.5)
                method = classification.get('method', 'rule_based')
                self.routing_stats["rule_based_routes"] += 1
            
            # å…¼å®¹å†å²é…ç½®ï¼šå°† sql_only ç»Ÿä¸€å½’å…¥ ANALYSIS
            if isinstance(route_type, str) and route_type.lower() == 'sql_only':
                route_type = RouteType.ANALYSIS.value
                classification['route'] = route_type
            
            # éªŒè¯è·¯ç”±ç±»å‹
            valid_routes = {
                RouteType.QA.value,
                RouteType.ANALYSIS.value,
                RouteType.ABORTED.value
            }
            if route_type not in valid_routes:
                logger.warning(f"è·¯ç”±ç±»å‹æ— æ•ˆ({route_type})ï¼Œä½¿ç”¨é»˜è®¤ANALYSIS")
                route_type = RouteType.ANALYSIS.value
                confidence = 0.5
                self.routing_stats["fallback_count"] += 1

            routing_info = {
                'route_type': route_type,
                'confidence': confidence,
                'reason': classification.get('reason'),
                'classification_time': classification.get('classification_time', 0),
                'plan': classification.get('suggested_plan') or [],
                'method': classification.get('method', 'ai')
            }

            # å°†è®¡åˆ’ã€æ­¥é•¿ç­‰å†™å…¥ä¸Šä¸‹æ–‡ï¼Œä¾›è§£é‡Šå™¨æ‰§è¡Œæ—¶å‚è€ƒ
            if routing_info['plan']:
                context['suggested_plan'] = routing_info['plan']

            thought_cfg = feature_flags.get('thought_stream') if isinstance(feature_flags.get('thought_stream'), dict) else {}
            template_key = 'template_en' if language == 'en' else 'template_zh'
            default_template = 'Step {index}: {summary}' if language == 'en' else 'æ­¥éª¤{index}ï¼š{summary}'
            context.setdefault('step_logging_enabled', thought_cfg.get('enabled', True))
            context.setdefault('step_template', thought_cfg.get(template_key, default_template))
            context.setdefault('step_min_words', thought_cfg.get('min_words', 3))
            context['route_type'] = route_type.upper() if isinstance(route_type, str) else route_type

            # è·¯ç”±æ‰§è¡Œå‰è¿›è¡Œæ•°æ®åº“å¥åº·æ£€æŸ¥ï¼ˆä»…é™éœ€è¦æ•°æ®åº“çš„è·¯çº¿ï¼‰
            requires_db = route_type == RouteType.ANALYSIS.value
            use_database = context.get('use_database', True) if isinstance(context, dict) else True
            guard_cfg = feature_flags.get('db_guard', {}) if isinstance(feature_flags.get('db_guard', {}), dict) else {}
            auto_check_db = guard_cfg.get('auto_check', True)
            warn_on_failure = guard_cfg.get('warn_on_failure', True)

            if requires_db and use_database and auto_check_db:
                if not self.database_guard:
                    logger.warning("æ•°æ®åº“å®ˆå«æœªåˆå§‹åŒ–ï¼Œè·³è¿‡è¿é€šæ€§æ£€æŸ¥")
                else:
                    guard_context = dict(context or {})
                    guard_context.setdefault('force_execute', guard_context.get('force_execute'))
                    db_check = self.database_guard.ensure_database_ready(
                        route_type=route_type,
                        context=guard_context,
                        guard_cfg=guard_cfg
                    )
                    if db_check.get('message') == 'force_execute':
                        self.routing_stats["forced_queries"] += 1
                    if not db_check.get('ok'):
                        self.routing_stats["aborted_queries"] += 1
                        logger.error("æ•°æ®åº“å¥åº·æ£€æŸ¥æœªé€šè¿‡ï¼Œç»ˆæ­¢æ‰§è¡Œ: %s", db_check.get('message'))
                        response_payload = build_guard_block_payload(
                            db_check,
                            guard_cfg,
                            query=query,
                            warn_on_failure=warn_on_failure,
                            route_type=route_type,
                            classification=classification,
                            routing_info=routing_info,
                            conversation_id=context.get('conversation_id') if context else None,
                            model_name=context.get('model_name') if context else None
                        )
                        return response_payload
            
            # è®°å½•è·¯ç”±å†³ç­–
            logger.info(f"ğŸ”„ è·¯ç”±å†³ç­–: {route_type} (ç½®ä¿¡åº¦: {confidence:.2f}, æ–¹æ³•: {method})")
            logger.info(f"   åŸå› : {classification.get('reason', 'æœªæä¾›')}")
            
            # è®°å½•AIåˆ†ç±»æ—¶é—´
            self.routing_stats["ai_classification_time"] += classification.get('classification_time', 0)
            
            # æ ¹æ®è·¯ç”±ç±»å‹æ‰§è¡Œ
            if route_type == RouteType.ABORTED.value:
                self.routing_stats["aborted_queries"] += 1
                logger.error("è·¯ç”±åˆ†ç±»å¤±è´¥ï¼Œè¿”å›å…œåº•å“åº”")
                return {
                    "success": False,
                    "error": "è·¯ç”±åˆ†ç±»å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
                    "routing_info": routing_info,
                    "query_type": RouteType.ABORTED.value
                }

            if route_type == RouteType.QA.value:
                result = self._execute_qa_response(query, classification, context)
                self.routing_stats["qa_queries"] += 1
            else:  # ç»Ÿä¸€èµ° ANALYSIS æµç¨‹
                result = self._execute_ai_analysis(query, context, classification)
                self.routing_stats["analysis_queries"] += 1
            
            # æ·»åŠ è·¯ç”±ä¿¡æ¯åˆ°ç»“æœ
            result['routing_info'] = routing_info
            result['classification'] = classification
            
            # è®¡ç®—æ—¶é—´èŠ‚çœï¼ˆå‡è®¾å®Œæ•´AIåˆ†æéœ€è¦5ç§’ï¼‰
            total_time = time.time() - start_time
            
            return result
            
        except Exception as e:
            logger.error(f"è·¯ç”±æ‰§è¡Œå¤±è´¥: {e}")
            self.routing_stats["fallback_count"] += 1
            # å¤±è´¥æ—¶é™çº§åˆ°AIå¤„ç†
            return self._execute_ai_analysis(query, context, {})
    
    def _prepare_routing_context(self, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """
        å‡†å¤‡è·¯ç”±ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        routing_context = {
            'db_type': 'MySQL/Doris',
            'tables': []
        }
        
        # è·å–å¯ç”¨è¡¨ä¿¡æ¯ï¼ˆä»…åœ¨æ•°æ®åº“å·²é…ç½®ä¸”æœªç¦ç”¨æ—¶ï¼‰
        if (
            self.database_manager
            and getattr(self.database_manager, 'is_configured', False)
            and not getattr(self.database_manager, '_global_disabled', False)
        ):
            try:
                tables = self.database_manager.get_tables()
                routing_context['tables'] = ', '.join(tables[:20])  # é™åˆ¶æ•°é‡
            except Exception:
                logger.debug("åŠ è½½è¡¨ä¿¡æ¯å¤±è´¥ï¼Œå¿½ç•¥ä»¥é¿å…å½±å“è·¯ç”±")
        
        return routing_context
    

    def _execute_qa_response(self, query: str, classification: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¾“å‡ºç¤¼è²Œçš„QAå“åº”ï¼Œå¼•å¯¼ç”¨æˆ·æä¾›æ•°æ®åº“ç›¸å…³é—®é¢˜
        """
        logger.info("æ‰§è¡ŒQAè·¯å¾„ - ç¤¼è²Œæ‹’ç»éæ•°æ®åº“é—®é¢˜")

        polite_message = (
            "æŠ±æ­‰ï¼Œæˆ‘æ˜¯ä¸€åæ•°æ®åº“æ•°æ®åŠ©æ‰‹ï¼Œç›®å‰åªèƒ½å¤„ç†ä¸æ•°æ®åº“å–æ•°æˆ–åˆ†æç›¸å…³çš„é—®é¢˜ã€‚"
            "è¯·æ‚¨æè¿°éœ€è¦æŸ¥è¯¢çš„æ•°æ®æˆ–æŒ‡æ ‡ï¼Œæˆ‘ä¼šå°½åŠ›å¸®å¿™ã€‚"
        )

        # æ”¯æŒè‡ªå®šä¹‰æç¤ºï¼ˆåç»­å¯ä»å‰ç«¯è®¾ç½®æ³¨å…¥ï¼‰
        custom_hint = None
        if context and isinstance(context, dict):
            custom_hint = context.get('qa_hint')
        if custom_hint:
            polite_message = custom_hint

        return {
            "success": True,
            "answer": polite_message,
            "messages": [
                {
                    "role": "assistant",
                    "type": "text",
                    "content": polite_message
                }
            ],
            "query_type": "qa",
            "model": "ai_router",
            "classification": classification
            }
    
    def _execute_ai_analysis(self, query: str, context: Dict[str, Any], classification: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡ŒAIåˆ†æï¼ˆç»Ÿä¸€å¤„ç†æ‰€æœ‰AIä»»åŠ¡ï¼‰
        æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦å¯è§†åŒ–ã€åˆ†æç­‰
        """
        # æ ¹æ®æŸ¥è¯¢å†…å®¹æ™ºèƒ½åˆ¤æ–­ä»»åŠ¡ç±»å‹
        query_lower = query.lower()
        task_hints = []
        
        if any(word in query_lower for word in ['å›¾', 'å›¾è¡¨', 'å¯è§†åŒ–', 'chart', 'graph', 'plot']):
            task_hints.append("visualization")
            logger.info("æ‰§è¡ŒAIåˆ†æè·¯å¾„ - æ£€æµ‹åˆ°å¯è§†åŒ–éœ€æ±‚")
        elif any(word in query_lower for word in ['åˆ†æ', 'è¶‹åŠ¿', 'é¢„æµ‹', 'analyze', 'trend']):
            task_hints.append("analysis")
            logger.info("æ‰§è¡ŒAIåˆ†æè·¯å¾„ - æ£€æµ‹åˆ°åˆ†æéœ€æ±‚")
        else:
            logger.info("æ‰§è¡ŒAIåˆ†æè·¯å¾„ - é€šç”¨AIå¤„ç†")
        
        # é˜²å¾¡æ€§ç¼–ç¨‹ï¼šç¡®ä¿contextä¸ä¸ºNone
        if context is None:
            context = {}
        context['route_type'] = 'ANALYSIS'
        
        if self.interpreter_manager:
            result = self.interpreter_manager.execute_query(
                query=query,
                context=context,
                model_name=context.get('model_name'),
                conversation_id=context.get('conversation_id'),
                language=context.get('language', 'zh')
            )
            result["query_type"] = "ai_analysis"
            return result
        else:
            return {
                "success": False,
                "error": "InterpreterManageræœªåˆå§‹åŒ–",
                "query_type": "ai_analysis"
        }
    
    def get_routing_stats(self) -> Dict[str, Any]:
        """
        è·å–è·¯ç”±ç»Ÿè®¡ä¿¡æ¯
        """
        stats = self.routing_stats.copy()
        
        # æ·»åŠ AIåˆ†ç±»å™¨ç»Ÿè®¡
        ai_stats = self.ai_classifier.get_stats()
        stats['ai_classifier'] = ai_stats
        
        # è®¡ç®—è·¯ç”±åˆ†å¸ƒï¼ˆç®€åŒ–ç‰ˆï¼‰
        if stats["total_queries"] > 0:
            total = stats["total_queries"]
            stats["route_distribution"] = {
                "qa": (stats["qa_queries"] / total * 100),
                "analysis": (stats["analysis_queries"] / total * 100),
                "aborted": (stats["aborted_queries"] / total * 100)
            }
            
            # å¹³å‡AIåˆ†ç±»æ—¶é—´
            stats["avg_ai_classification_time"] = (
                stats["ai_classification_time"] / total
            )
            
            # å¹³å‡èŠ‚çœæ—¶é—´
            stats["avg_time_saved"] = stats["total_time_saved"] / total
        
        return stats
    
    def _load_routing_prompt(self) -> str:
        """
        ä»é…ç½®æ–‡ä»¶åŠ è½½routing prompt
        
        Returns:
            è·¯ç”±promptå­—ç¬¦ä¸²ï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å›None
        """
        try:
            import json
            import os
            config_path = os.path.join(os.path.dirname(__file__), 'prompt_config.json')
            
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    return config.get('routing')
        except Exception as e:
            logger.warning(f"åŠ è½½routing promptå¤±è´¥: {e}")
        
        return None
    
    def update_routing_prompt(self, new_prompt: str):
        """
        æ›´æ–°è·¯ç”±prompt
        
        Args:
            new_prompt: æ–°çš„è·¯ç”±prompt
        """
        self.ai_classifier.update_routing_prompt(new_prompt)
        logger.info("è·¯ç”±promptå·²æ›´æ–°")
