"""èŠå¤©APIè“å›¾ - å¤„ç†ç”¨æˆ·æŸ¥è¯¢å’Œæµå¼å“åº”"""
import os
import json
import logging
import re
import uuid as uuid_module
from flask import Blueprint, request, jsonify, Response
from datetime import datetime

from backend.auth import optional_auth
from backend.rate_limiter import rate_limit
from backend.config_loader import ConfigLoader
from backend.core import service_container
from backend.utils import sse_format, generate_progress_plan, dynamic_rate_limit

logger = logging.getLogger(__name__)

# åˆ›å»ºè“å›¾
chat_bp = Blueprint('chat', __name__, url_prefix='/api')

services = service_container


def _refresh_manager_aliases():
    """åˆ·æ–°ç®¡ç†å™¨åˆ«å"""
    pass  # ç›´æ¥ä½¿ç”¨servicesè®¿é—®


def _get_stop_status(conversation_id):
    """çº¿ç¨‹å®‰å…¨åœ°è·å–åœæ­¢çŠ¶æ€"""
    return services.get_stop_status(conversation_id)


def ensure_database_manager(force_reload: bool = False) -> bool:
    """ç¡®ä¿ database_manager å·²å‡†å¤‡å¥½"""
    return services.ensure_database_manager(force_reload=force_reload)


def ensure_history_manager(force_reload: bool = False) -> bool:
    """ç¡®ä¿ history_manager å·²åˆå§‹åŒ–"""
    return services.ensure_history_manager(force_reload=force_reload)


def init_managers(force_reload: bool = False):
    """åˆå§‹åŒ–å„ä¸ªç®¡ç†å™¨"""
    services.init_managers(force_reload=force_reload)


@chat_bp.route('/chat/stream', methods=['GET'])
@optional_auth
@rate_limit(max_requests=20, window_seconds=60)
def chat_stream():
    """SSEæµå¼æŸ¥è¯¢ï¼šä»…æ¨é€å‹å¥½çš„è¿›åº¦ä¸æœ€ç»ˆç»“æœï¼Œä¸åŒ…å«ä»£ç ã€‚"""
    try:
        interpreter_manager = services.interpreter_manager
        history_manager = services.history_manager
        smart_router = services.smart_router

        if interpreter_manager is None:
            return Response(sse_format('error', {"error": "LLM è§£é‡Šå™¨æœªåˆå§‹åŒ–"}), mimetype='text/event-stream')

        # è¯»å–å‚æ•°ï¼ˆEventSourceä¸ºGETï¼‰
        user_query = request.args.get('query', '')
        model_name = request.args.get('model')
        use_database = request.args.get('use_database', 'true').lower() != 'false'
        context_rounds = int(request.args.get('context_rounds', '3') or 3)
        user_language = request.args.get('language', 'zh')
        requested_conversation_id = request.args.get('conversation_id')

        if not user_query:
            return Response(sse_format('error', {"error": "æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º"}), mimetype='text/event-stream')

        # åˆ›å»ºæˆ–å¤ç”¨ä¼šè¯ID
        conv_id = requested_conversation_id or None
        if history_manager:
            title = user_query[:50] + ('...' if len(user_query) > 50 else '')
            existing_conversation = None
            if conv_id:
                try:
                    existing_conversation = history_manager.get_conversation_history(conv_id)
                except Exception as exc:
                    logger.warning(f"è¯»å–ä¼šè¯ {conv_id} å¤±è´¥ï¼Œåˆ›å»ºæ–°ä¼šè¯: {exc}")
                    existing_conversation = None
            if not conv_id or not existing_conversation:
                conv_id = history_manager.create_conversation(title=title, model=model_name or 'default')
        else:
            conv_id = conv_id or str(uuid_module.uuid4())

        # å¦‚æœæ•°æ®åº“ä¸å¯ç”¨ï¼Œè‡ªåŠ¨é™çº§
        if use_database and not ensure_database_manager():
            logger.warning("è¯·æ±‚ä½¿ç”¨æ•°æ®åº“ï¼Œä½†å½“å‰æ•°æ®åº“ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºçº¯AIæ¨¡å¼")
            use_database = False

        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        if history_manager and conv_id and user_query:
            try:
                history_manager.add_message(
                    conversation_id=conv_id,
                    message_type="user",
                    content=user_query,
                    context={
                        "model": model_name,
                        "use_database": use_database,
                        "context_rounds": context_rounds
                    }
                )
            except Exception as exc:
                logger.warning(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²å¤±è´¥: {exc}")

        # æ ‡è®°æŸ¥è¯¢å¼€å§‹
        services.mark_query_started(conv_id)

        # è®¾ç½®ä¸Šä¸‹æ–‡è½®æ•°
        if interpreter_manager and context_rounds:
            interpreter_manager.max_history_rounds = context_rounds

        def generate():
            try:
                # èµ·å§‹äº‹ä»¶
                yield sse_format('progress', {'stage': 'start', 'message': 'å¼€å§‹å¤„ç†è¯·æ±‚â€¦', 'conversation_id': conv_id})

                # è·¯ç”±é˜¶æ®µ
                route_info = {'route_type': 'ai_analysis', 'confidence': 0}
                config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'config.json')
                smart_enabled = False
                try:
                    if os.path.exists(config_path):
                        with open(config_path, 'r', encoding='utf-8') as f:
                            cfg = json.load(f)
                            smart_enabled = cfg.get('features', {}).get('smart_routing', {}).get('enabled', False)
                except Exception:
                    smart_enabled = False

                if smart_router and smart_enabled:
                    yield sse_format('progress', {'stage': 'classify', 'message': 'æ­£åœ¨åˆ¤æ–­æœ€ä½³æ‰§è¡Œè·¯å¾„â€¦'})
                    router_ctx = {
                        'model_name': model_name,
                        'conversation_id': conv_id,
                        'language': user_language,
                        'use_database': use_database,
                        'context_rounds': context_rounds,
                        'stop_checker': lambda: _get_stop_status(conv_id),
                    }
                    try:
                        classification = smart_router.ai_classifier.classify(user_query, smart_router._prepare_routing_context(router_ctx)) if smart_router.ai_classifier else {}
                        route_type = str(classification.get('route', 'ai_analysis')).lower()
                        route_info['route_type'] = route_type
                        route_info['confidence'] = classification.get('confidence', 0)
                        yield sse_format('progress', {'stage': 'route', 'message': f"æ‰§è¡Œè·¯å¾„ï¼š{route_type}", 'route': route_info})
                    except Exception:
                        yield sse_format('progress', {'stage': 'route', 'message': 'ä½¿ç”¨é»˜è®¤AIåˆ†æè·¯å¾„'})

                # ç”Ÿæˆè¿›åº¦è®¡åˆ’ï¼ˆçŸ­æ ‡ç­¾ï¼‰
                try:
                    labels = generate_progress_plan(user_query, route_info.get('route_type', 'ai_analysis'), user_language)
                    yield sse_format('progress_plan', {'labels': labels})
                except Exception:
                    pass

                # æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
                context = {}
                if use_database:
                    try:
                        db_config = ConfigLoader.get_database_config()
                        context['connection_info'] = {
                            'host': db_config['host'],
                            'port': db_config['port'],
                            'user': db_config['user'],
                            'password': db_config['password'],
                            'database': db_config.get('database', '')
                        }
                    except Exception:
                        pass

                # å‹å¥½é˜¶æ®µæç¤º
                if route_info.get('route_type') == 'direct_sql':
                    yield sse_format('progress', {'stage': 'execute', 'message': 'æ­£åœ¨æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢â€¦'})
                else:
                    yield sse_format('progress', {'stage': 'analyze', 'message': 'æ­£åœ¨åˆ†ææ•°æ®ä¸ç”Ÿæˆå›¾è¡¨â€¦'})

                # æ‰§è¡ŒæŸ¥è¯¢
                result = interpreter_manager.execute_query(
                    user_query,
                    context=context,
                    model_name=model_name,
                    conversation_id=conv_id,
                    stop_checker=lambda: _get_stop_status(conv_id),
                    language=user_language
                )

                # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°å†å²
                if history_manager and conv_id:
                    try:
                        assistant_content = result.get('result', result.get('error', 'æ‰§è¡Œå¤±è´¥'))
                        execution_details = None
                        if result.get('success'):
                            execution_details = {
                                "sql": result.get('sql'),
                                "execution_time": result.get('execution_time'),
                                "rows_affected": result.get('rows_count'),
                                "visualization": result.get('visualization'),
                                "model": result.get('model')
                            }
                        if isinstance(assistant_content, dict) and 'content' in assistant_content:
                            content_to_save = json.dumps({"type": "dual_view", "data": assistant_content}, ensure_ascii=False)
                        elif isinstance(assistant_content, list):
                            content_to_save = json.dumps({"type": "raw_output", "data": assistant_content}, ensure_ascii=False)
                        elif not isinstance(assistant_content, str):
                            content_to_save = json.dumps(assistant_content, ensure_ascii=False)
                        else:
                            content_to_save = assistant_content
                        history_manager.add_message(
                            conversation_id=conv_id,
                            message_type="assistant",
                            content=content_to_save,
                            execution_details=execution_details
                        )
                    except Exception as exc:
                        logger.warning(f"ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²å¤±è´¥: {exc}")

                # ç»“æœäº‹ä»¶
                yield sse_format('result', {
                    'success': result.get('success', False),
                    'result': result.get('result') or result.get('error'),
                    'model': result.get('model'),
                    'conversation_id': conv_id
                })

                yield sse_format('done', {'conversation_id': conv_id})

            except GeneratorExit:
                # å®¢æˆ·ç«¯æ–­å¼€
                services.mark_query_should_stop(conv_id)
                if interpreter_manager:
                    interpreter_manager.stop_query(conv_id)
            except Exception as e:
                yield sse_format('error', {'error': str(e), 'conversation_id': conv_id})
            finally:
                services.clear_active_query(conv_id)

        headers = {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
        return Response(generate(), headers=headers)

    except Exception as e:
        return Response(sse_format('error', {'error': str(e)}), mimetype='text/event-stream')


@chat_bp.route('/chat', methods=['POST'])
@optional_auth
@dynamic_rate_limit(max_requests=30, window_seconds=60)
def chat():
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    try:
        # æƒ°æ€§åˆå§‹åŒ–
        if services.interpreter_manager is None:
            try:
                init_managers()
            except Exception:
                logger.error("InterpreterManager æœªåˆå§‹åŒ–")
        
        interpreter_manager = services.interpreter_manager
        history_manager = services.history_manager
        smart_router = services.smart_router
        database_manager = services.database_manager

        data = request.get_json(silent=True) or {}
        user_query = data.get('query') or data.get('message') or ''
        model_name = ConfigLoader.normalize_model_id(data.get('model')) if data.get('model') else None

        if not ensure_history_manager() and data.get('use_history', True):
            logger.warning("å†å²è®°å½•æœªå¯ç”¨ï¼ŒèŠå¤©è®°å½•å°†ä¸ä¼šè¢«ä¿å­˜")
        
        use_database = data.get('use_database', True)
        conversation_id = data.get('conversation_id')
        context_rounds = data.get('context_rounds', 3)
        user_language = data.get('language', 'zh')
        force_execute = bool(data.get('force_execute'))
        
        # ç®€æ˜“SSEå…¼å®¹
        if data.get('stream') is True:
            def _mini_stream():
                yield "data: {\"status\": \"processing\"}\n\n"
                yield "data: {\"status\": \"done\"}\n\n"
            return Response(_mini_stream(), mimetype='text/event-stream')
        
        # åˆ›å»ºæˆ–è·å–ä¼šè¯ID
        if not conversation_id:
            if history_manager:
                has_chinese = bool(re.search(r'[\u4e00-\u9fff]', user_query))
                query_prefix = "æŸ¥è¯¢: " if has_chinese else "Query: "
                title = f"{query_prefix}{user_query[:50]}..." if len(user_query) > 50 else user_query
                conversation_id = history_manager.create_conversation(
                    title=title,
                    model=model_name or "default",
                    database_name=data.get('database')
                )
                logger.info(f"åˆ›å»ºæ–°å¯¹è¯: {conversation_id}")
            else:
                conversation_id = str(uuid_module.uuid4())
                logger.warning("history_manageræœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ä¸´æ—¶ID")
        
        # è®¾ç½®ä¸Šä¸‹æ–‡è½®æ•°
        if interpreter_manager and context_rounds:
            interpreter_manager.max_history_rounds = context_rounds
        
        if not user_query:
            return jsonify({"error": "message is required"}), 400
        
        logger.info(f"æ”¶åˆ°æŸ¥è¯¢: {user_query[:100]}...")
        
        # ç®€å•çš„æ„å›¾è¯†åˆ«
        greetings = ['ä½ å¥½', 'hello', 'hi', 'æ—©ä¸Šå¥½', 'ä¸‹åˆå¥½', 'æ™šä¸Šå¥½', 'å—¨']
        farewells = ['å†è§', 'æ‹œæ‹œ', 'bye', 'goodbye', 'æ™šå®‰']
        query_lower = user_query.lower().strip()
        
        # é—®å€™è¯­å¤„ç†
        if any(greeting in query_lower for greeting in greetings):
            if history_manager and conversation_id:
                history_manager.add_message(
                    conversation_id=conversation_id,
                    message_type="user",
                    content=user_query,
                    context={"model": model_name, "type": "greeting"}
                )
                greeting_response = "QueryGPT æ•°æ®åˆ†æç³»ç»Ÿ\n\nå¯æä¾›ï¼š\nâ€¢ æ•°æ®åº“æŸ¥è¯¢åˆ†æ\nâ€¢ å›¾è¡¨ç”Ÿæˆï¼ˆæŸ±çŠ¶å›¾ã€é¥¼å›¾ã€æŠ˜çº¿å›¾ï¼‰\nâ€¢ æ•°æ®æŠ¥è¡¨å¯¼å‡º\n\nç¤ºä¾‹æŸ¥è¯¢ï¼š\n- æŸ¥è¯¢ä¸Šæœˆé”€å”®æ•°æ®\n- æŒ‰éƒ¨é—¨ç»Ÿè®¡ä»Šå¹´ä¸šç»©\n- ç”Ÿæˆäº§å“é”€é‡è¶‹åŠ¿å›¾"
                history_manager.add_message(
                    conversation_id=conversation_id,
                    message_type="assistant",
                    content=greeting_response
                )
            return jsonify({
                "success": True,
                "result": {
                    "content": [{
                        "type": "text",
                        "content": greeting_response
                    }]
                },
                "model": model_name or "system",
                "conversation_id": conversation_id,
                "timestamp": datetime.now().isoformat()
            })
        
        # å‘Šåˆ«è¯­å¤„ç†
        if any(farewell in query_lower for farewell in farewells):
            if history_manager and conversation_id:
                history_manager.add_message(
                    conversation_id=conversation_id,
                    message_type="user",
                    content=user_query,
                    context={"model": model_name, "type": "farewell"}
                )
                farewell_response = "ä¼šè¯ç»“æŸ"
                history_manager.add_message(
                    conversation_id=conversation_id,
                    message_type="assistant",
                    content=farewell_response
                )
            return jsonify({
                "success": True,
                "result": {
                    "content": [{
                        "type": "text",
                        "content": "ä¼šè¯ç»“æŸ"
                    }]
                },
                "model": model_name or "system",
                "conversation_id": conversation_id,
                "timestamp": datetime.now().isoformat()
            })
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        context = {}
        config_snapshot = ConfigLoader.get_config()
        feature_section = config_snapshot.get('features', {}) if isinstance(config_snapshot.get('features', {}), dict) else {}
        feature_cfg = feature_section
        thought_cfg = feature_cfg.get('thought_stream') if isinstance(feature_cfg.get('thought_stream'), dict) else {}
        template_key = 'template_en' if user_language == 'en' else 'template_zh'
        default_template = 'Step {index}: {summary}' if user_language == 'en' else 'æ­¥éª¤{index}ï¼š{summary}'
        context['step_logging_enabled'] = thought_cfg.get('enabled', True)
        context['step_template'] = thought_cfg.get(template_key, default_template)
        context['step_min_words'] = thought_cfg.get('min_words', 3)
        if use_database:
            if not ensure_database_manager():
                logger.warning("è¯·æ±‚ä½¿ç”¨æ•°æ®åº“ï¼Œä½†æœªæ£€æµ‹åˆ°æœ‰æ•ˆé…ç½®ï¼Œè‡ªåŠ¨é™çº§ä¸ºéæ•°æ®åº“æ¨¡å¼")
                use_database = False
            else:
                db_config = ConfigLoader.get_database_config()
                context['connection_info'] = {
                    'host': db_config['host'],
                    'port': db_config['port'],
                    'user': db_config['user'],
                    'password': db_config['password'],
                    'database': db_config.get('database', '')
                }
                if database_manager and getattr(database_manager, 'is_configured', False):
                    global_disabled = getattr(type(database_manager), 'GLOBAL_DISABLED', False)
                    if not global_disabled:
                        try:
                            db_list = database_manager.get_database_list()
                            context['available_databases'] = db_list
                        except Exception as e:
                            logger.warning(f"è·å–æ•°æ®åº“åˆ—è¡¨å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ: {e}")
        
        full_query = user_query
        
        # æ ‡è®°æŸ¥è¯¢å¼€å§‹
        services.mark_query_started(conversation_id)
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²è®°å½•
        if history_manager and conversation_id:
            history_manager.add_message(
                conversation_id=conversation_id,
                message_type="user",
                content=user_query,
                context={
                    "model": model_name,
                    "use_database": use_database,
                    "context_rounds": context_rounds
                }
            )
        
        try:
            # æ£€æŸ¥æ™ºèƒ½è·¯ç”±æ˜¯å¦å¯ç”¨
            smart_routing_cfg = feature_cfg.get('smart_routing') if isinstance(feature_cfg.get('smart_routing'), dict) else {}
            smart_routing_enabled = smart_routing_cfg.get('enabled', False)
            
            # ä½¿ç”¨æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ
            if smart_router and smart_routing_enabled:
                logger.info("ğŸš€ ä½¿ç”¨æ™ºèƒ½è·¯ç”±ç³»ç»Ÿå¤„ç†æŸ¥è¯¢ [BETA]")
                router_context = {
                    'model_name': model_name,
                    'conversation_id': conversation_id,
                    'language': user_language,
                    'use_database': use_database,
                    'context_rounds': context_rounds,
                    'stop_checker': lambda: _get_stop_status(conversation_id),
                    'connection_info': context.get('connection_info', {}),
                    'force_execute': force_execute,
                    'feature_flags': feature_cfg,
                    'step_logging_enabled': context.get('step_logging_enabled'),
                    'step_template': context.get('step_template'),
                    'step_min_words': context.get('step_min_words')
                }
                result = smart_router.route(full_query, router_context)
                if result.get('status') == 'db_unavailable':
                    result.update({
                        "conversation_id": conversation_id,
                        "model": model_name or "smart_router",
                        "timestamp": datetime.now().isoformat()
                    })
                    return jsonify(result)
                if 'query_type' in result:
                    logger.info(f"ğŸ“Š æŸ¥è¯¢ç±»å‹: {result['query_type']}, æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 'N/A')}s")
                result['smart_routing_used'] = True
            else:
                if not smart_routing_enabled:
                    logger.info("æ™ºèƒ½è·¯ç”±å·²ç¦ç”¨ï¼Œä½¿ç”¨æ ‡å‡†AIæµç¨‹")
                else:
                    logger.info("æ™ºèƒ½è·¯ç”±æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨æ ‡å‡†AIæµç¨‹")
                result = interpreter_manager.execute_query(
                    full_query,
                    context=context,
                    model_name=model_name,
                    conversation_id=conversation_id,
                    stop_checker=lambda: _get_stop_status(conversation_id),
                    language=user_language
                )
                result['smart_routing_used'] = False
        finally:
            services.clear_active_query(conversation_id)
        
        # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°å†å²è®°å½•
        if history_manager and conversation_id:
            execution_details = None
            assistant_content = result.get('result', result.get('error', 'æ‰§è¡Œå¤±è´¥'))
            if result.get('success'):
                execution_details = {
                    "sql": result.get('sql'),
                    "execution_time": result.get('execution_time'),
                    "rows_affected": result.get('rows_count'),
                    "visualization": result.get('visualization'),
                    "model": result.get('model')
                }
            if isinstance(assistant_content, dict) and 'content' in assistant_content:
                content_to_save = json.dumps({"type": "dual_view", "data": assistant_content}, ensure_ascii=False)
            elif isinstance(assistant_content, list):
                content_to_save = json.dumps({"type": "raw_output", "data": assistant_content}, ensure_ascii=False)
            elif not isinstance(assistant_content, str):
                content_to_save = json.dumps(assistant_content, ensure_ascii=False)
            else:
                content_to_save = assistant_content
            history_manager.add_message(
                conversation_id=conversation_id,
                message_type="assistant",
                content=content_to_save,
                execution_details=execution_details
            )
        
        if result['success']:
            resp_payload = {
                "success": True,
                "result": result['result'],
                "model": result['model'],
                "conversation_id": conversation_id,
                "timestamp": datetime.now().isoformat()
            }
            if result.get('routing_info'):
                resp_payload['routing_info'] = result['routing_info']
            if result.get('classification'):
                resp_payload['classification'] = result['classification']
            sql_text = result.get('sql')
            if not sql_text and isinstance(result.get('result'), list):
                for item in result['result']:
                    if isinstance(item, dict) and item.get('type') == 'code' and item.get('format') == 'sql':
                        sql_text = item.get('content')
                        break
            resp_payload['sql'] = sql_text
            if isinstance(result.get('result'), list):
                parts = []
                for item in result['result']:
                    content = item.get('content') if isinstance(item, dict) else None
                    if content:
                        parts.append(str(content))
                resp_payload['response'] = '\n'.join(parts)[:2000]
            else:
                resp_payload['response'] = str(result.get('result'))[:2000]
            return jsonify(resp_payload)
        elif result.get('interrupted'):
            if history_manager and conversation_id:
                try:
                    history_manager.remove_last_message(conversation_id, message_type='user', delete_empty=False)
                except Exception as cleanup_err:
                    logger.warning(f"æ¸…ç†ä¸­æ–­æ¶ˆæ¯å¤±è´¥: {cleanup_err}")
            return jsonify({
                "success": False,
                "interrupted": True,
                "error": result.get('error', 'æŸ¥è¯¢è¢«ç”¨æˆ·ä¸­æ–­'),
                "model": result['model'],
                "conversation_id": conversation_id,
                "partial_result": result.get('partial_result'),
                "timestamp": datetime.now().isoformat()
            }), 200
        else:
            return jsonify({
                "success": False,
                "error": result['error'],
                "model": result['model'],
                "conversation_id": conversation_id,
                "timestamp": datetime.now().isoformat()
            }), 500
            
    except Exception as e:
        logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500


@chat_bp.route('/stop_query', methods=['POST'])
def stop_query():
    """åœæ­¢æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢"""
    try:
        data = request.json
        conversation_id = data.get('conversation_id')
        
        logger.info(f"æ”¶åˆ°åœæ­¢æŸ¥è¯¢è¯·æ±‚: conversation_id={conversation_id}")
        
        if not conversation_id:
            logger.warning("åœæ­¢æŸ¥è¯¢è¯·æ±‚ç¼ºå°‘ä¼šè¯ID")
            return jsonify({"error": "éœ€è¦æä¾›ä¼šè¯ID"}), 400
        
        query_found = False
        active_snapshot = services.active_queries_snapshot()
        logger.info("å½“å‰æ´»åŠ¨æŸ¥è¯¢: %s", list(active_snapshot.keys()))
        if conversation_id in active_snapshot:
            services.mark_query_should_stop(conversation_id)
            query_found = True
            logger.info(f"å·²è®¾ç½®åœæ­¢æ ‡å¿—: {conversation_id}")

        interpreter = services.interpreter_manager
        if interpreter:
            logger.info(f"è°ƒç”¨interpreter_manager.stop_query: {conversation_id}")
            interpreter.stop_query(conversation_id)
        
        if query_found:
            logger.info(f"åœæ­¢æŸ¥è¯¢è¯·æ±‚å¤„ç†æˆåŠŸ: {conversation_id}")
            return jsonify({
                "success": True,
                "message": "æŸ¥è¯¢åœæ­¢è¯·æ±‚å·²å‘é€",
                "conversation_id": conversation_id,
                "debug": {
                    "query_found": query_found,
                    "active_queries_count": len(active_snapshot)
                }
            })
        else:
            logger.warning(f"æœªæ‰¾åˆ°æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢: {conversation_id}")
            return jsonify({
                "success": False,
                "message": "æ²¡æœ‰æ‰¾åˆ°æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢",
                "conversation_id": conversation_id,
                "debug": {
                    "conversation_id": conversation_id,
                    "active_queries": list(active_snapshot.keys())
                }
            })
    except Exception as e:
        logger.error(f"åœæ­¢æŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

